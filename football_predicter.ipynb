{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd3bf03",
   "metadata": {},
   "source": [
    "# ðŸ§  Premier League Predictor v3.0 (Smart Caching, Betting Odds & Grid Search)\n",
    "\n",
    "Nesta versÃ£o, vamos profissionalizar o pipeline:\n",
    "1.  **Smart Loading:** SÃ³ baixa dados se nÃ£o tivermos o ficheiro local.\n",
    "2.  **Betting Insights:** Usar as odds da Bet365 como features (representam o \"consenso do mercado\").\n",
    "3.  **Grid Search:** O computador vai testar vÃ¡rias configuraÃ§Ãµes do XGBoost para encontrar a melhor accuracy possÃ­vel automaticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62edbbd4",
   "metadata": {},
   "source": [
    "Imports e ConfiguraÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14553427",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition (Recolha de Dados)\n",
    "Vamos buscar dados reais do `football-data.co.uk`. Vamos carregar vÃ¡rias temporadas consecutivas para que o modelo tenha histÃ³rico suficiente para aprender padrÃµes.\n",
    "\n",
    "* **FTHG**: Full Time Home Goals\n",
    "* **FTAG**: Full Time Away Goals\n",
    "* **FTR**: Full Time Result (H=Home, D=Draw, A=Away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27652b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'premier_league_v3_full.csv'\n",
    "\n",
    "def get_data(start_year, end_year):\n",
    "    # 1. Verificar se ficheiro existe localmente\n",
    "    if os.path.exists(DATA_FILE):\n",
    "        print(f\"Ficheiro local '{DATA_FILE}' encontrado! A carregar...\")\n",
    "        df = pd.read_csv(DATA_FILE)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        # Se quiseres atualizar dados recentes, apaga o ficheiro .csv da pasta e corre isto de novo\n",
    "        return df\n",
    "    \n",
    "    # 2. Se nÃ£o existe, sacar da net\n",
    "    print(\"Ficheiro nÃ£o encontrado. A fazer download da internet...\")\n",
    "    base_url = \"https://www.football-data.co.uk/mmz4281/{}/{}.csv\"\n",
    "    dfs = []\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        season_str = f\"{str(year)[-2:]}{str(year+1)[-2:]}\"\n",
    "        url = base_url.format(season_str, \"E0\")\n",
    "        try:\n",
    "            df = pd.read_csv(url)\n",
    "            df['Season'] = year\n",
    "            # Normalizar Data\n",
    "            df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no ano {year}: {e}\")\n",
    "            \n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "    full_df = full_df.dropna(subset=['Date', 'FTR'])\n",
    "    full_df = full_df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Guardar para a prÃ³xima vez\n",
    "    full_df.to_csv(DATA_FILE, index=False)\n",
    "    print(\"âœ… Download concluÃ­do e guardado no PC.\")\n",
    "    return full_df\n",
    "\n",
    "# Carregar dados\n",
    "df = get_data(2005, 2025)\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a02a0a",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Completa (ELO + Stats + Odds)\n",
    "\n",
    "Aqui adicionamos as colunas B365H, B365D, B365A (Odds da Bet365)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f923a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df, window=5):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- 1. ELO SYSTEM ---\n",
    "    elo_dict = {}\n",
    "    df['HomeElo'] = 1500.0\n",
    "    df['AwayElo'] = 1500.0\n",
    "    k_factor = 20\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        h, a, res = row['HomeTeam'], row['AwayTeam'], row['FTR']\n",
    "        h_elo = elo_dict.get(h, 1500.0)\n",
    "        a_elo = elo_dict.get(a, 1500.0)\n",
    "        \n",
    "        df.at[i, 'HomeElo'] = h_elo\n",
    "        df.at[i, 'AwayElo'] = a_elo\n",
    "        \n",
    "        if res == 'H': val = 1\n",
    "        elif res == 'D': val = 0.5\n",
    "        else: val = 0\n",
    "        \n",
    "        exp_h = 1 / (1 + 10**((a_elo - h_elo)/400))\n",
    "        new_h = h_elo + k_factor * (val - exp_h)\n",
    "        new_a = a_elo + k_factor * ((1-val) - (1-exp_h))\n",
    "        \n",
    "        elo_dict[h] = new_h\n",
    "        elo_dict[a] = new_a\n",
    "        \n",
    "    df['EloDiff'] = df['HomeElo'] - df['AwayElo']\n",
    "    \n",
    "    # --- 2. ROLLING STATS ---\n",
    "    home_stats = df[['Date', 'HomeTeam', 'FTHG', 'FTAG', 'HS', 'HST', 'HC']].copy()\n",
    "    home_stats.columns = ['Date', 'Team', 'Goals', 'Conceded', 'Shots', 'SoT', 'Corners']\n",
    "    home_stats['Points'] = df['FTR'].map({'H':3, 'D':1, 'A':0})\n",
    "    \n",
    "    away_stats = df[['Date', 'AwayTeam', 'FTAG', 'FTHG', 'AS', 'AST', 'AC']].copy()\n",
    "    away_stats.columns = ['Date', 'Team', 'Goals', 'Conceded', 'Shots', 'SoT', 'Corners']\n",
    "    away_stats['Points'] = df['FTR'].map({'A':3, 'D':1, 'H':0})\n",
    "    \n",
    "    all_stats = pd.concat([home_stats, away_stats]).sort_values(['Team', 'Date'])\n",
    "    \n",
    "    metrics = ['Points', 'Goals', 'Conceded', 'Shots', 'SoT', 'Corners']\n",
    "    for m in metrics:\n",
    "        all_stats[f'Avg_{m}'] = all_stats.groupby('Team')[m].transform(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=3).mean()\n",
    "        )\n",
    "    \n",
    "    # Merge Home rolling\n",
    "    df = df.merge(\n",
    "        all_stats[['Date', 'Team'] + [f'Avg_{m}' for m in metrics]],\n",
    "        left_on=['Date', 'HomeTeam'],\n",
    "        right_on=['Date', 'Team'],\n",
    "        how='left'\n",
    "    ).drop(columns=['Team'])\n",
    "    df = df.rename(columns={f'Avg_{m}': f'Home_{m}' for m in metrics})\n",
    "    \n",
    "    # Merge Away rolling\n",
    "    df = df.merge(\n",
    "        all_stats[['Date', 'Team'] + [f'Avg_{m}' for m in metrics]],\n",
    "        left_on=['Date', 'AwayTeam'],\n",
    "        right_on=['Date', 'Team'],\n",
    "        how='left'\n",
    "    ).drop(columns=['Team'])\n",
    "    df = df.rename(columns={f'Avg_{m}': f'Away_{m}' for m in metrics})\n",
    "    \n",
    "    # --- 3. BETTING ODDS ---\n",
    "    if 'B365H' in df.columns:\n",
    "        df['Prob_Home'] = 1 / df['B365H']\n",
    "        df['Prob_Draw'] = 1 / df['B365D']\n",
    "        df['Prob_Away'] = 1 / df['B365A']\n",
    "        df = df.dropna(subset=['Prob_Home'])\n",
    "    \n",
    "    # Preencher sÃ³ as rolling averages\n",
    "    rolling_cols = [f for f in df.columns if f.startswith(\"Home_\") or f.startswith(\"Away_\")]\n",
    "    df[rolling_cols] = df[rolling_cols].fillna(0)\n",
    "    \n",
    "    # Remover colunas totalmente vazias\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    return df, elo_dict\n",
    "\n",
    "# Aplicar e verificar colunas\n",
    "df_processed, elo_tracker = prepare_features(df)\n",
    "print(\"Colunas disponÃ­veis para treino:\", df_processed.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5a89c",
   "metadata": {},
   "source": [
    "## 3. PreparaÃ§Ã£o e Treino do Modelo\n",
    "Treino Intensivo: Grid Search (Hyperparameter Tuning) Aqui Ã© onde \"apertamos\" o modelo. Vamos testar vÃ¡rias combinaÃ§Ãµes. Nota: Isto pode demorar 2 ou 3 minutos a correr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e9837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados\n",
    "features = ['HomeElo', 'AwayElo', 'EloDiff', \n",
    "            'Prob_Home', 'Prob_Draw', 'Prob_Away'] + \\\n",
    "           [c for c in df_processed.columns if 'Home_' in c or 'Away_' in c]\n",
    "\n",
    "# Filtrar apenas as colunas que realmente existem (caso falte alguma)\n",
    "features = [f for f in features if f in df_processed.columns]\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_processed['Target'] = le.fit_transform(df_processed['FTR'])\n",
    "\n",
    "# Split\n",
    "split = int(len(df_processed) * 0.80) # Treinar com 80%, testar com 20% (mais recente)\n",
    "train = df_processed.iloc[:split]\n",
    "test = df_processed.iloc[split:]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train['Target']\n",
    "X_test = test[features]\n",
    "y_test = test['Target']\n",
    "\n",
    "# --- GRID SEARCH ---\n",
    "print(\"A iniciar Treino Intensivo (Grid Search)...\")\n",
    "\n",
    "# Definir o modelo base\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, objective='multi:softprob', eval_metric='mlogloss')\n",
    "\n",
    "# Definir a grelha de parametros para testar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],      # Quantas Ã¡rvores?\n",
    "    'max_depth': [3, 4, 5],          # QuÃ£o complexa Ã© cada Ã¡rvore?\n",
    "    'learning_rate': [0.01, 0.05],   # QuÃ£o rÃ¡pido aprende?\n",
    "    'subsample': [0.8],              # Evitar overfitting\n",
    "}\n",
    "\n",
    "# Configurar a procura\n",
    "# TimeSeriesSplit garante que a validaÃ§Ã£o cruzada respeita o tempo (nÃ£o treina no futuro)\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=tscv, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nMelhores ParÃ¢metros encontrados: {grid_search.best_params_}\")\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da910c6c",
   "metadata": {},
   "source": [
    "### Matriz de ConfusÃ£o e accuracy\n",
    "Vamos ver visualmente onde o modelo erra.\n",
    "* Eixo Y: O que realmente aconteceu.\n",
    "* Eixo X: O que o modelo previu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o melhor modelo no set de teste (que ele nunca viu)\n",
    "preds = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(f\"\\nAccuracy Final (Otimizada): {acc:.2%}\")\n",
    "\n",
    "# Matriz de ConfusÃ£o\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Matriz de ConfusÃ£o (XGBoost)')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Previsto')\n",
    "plt.show()\n",
    "\n",
    "# Ver importÃ¢ncia das features\n",
    "# Vais ver que 'Prob_Home' (Odds) e 'EloDiff' vÃ£o estar no topo\n",
    "importances = pd.Series(best_model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "importances.head(15).plot(kind='barh')\n",
    "plt.title(\"Top 15 Fatores Mais Importantes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7176fed1",
   "metadata": {},
   "source": [
    "## 4. AplicaÃ§Ã£o na \"Vida Real\"\n",
    "Aqui estÃ¡ a funÃ§Ã£o final. Ela usa o dicionÃ¡rio `current_elo` (que contÃ©m os valores mais recentes apÃ³s o Ãºltimo jogo do dataset) para fazer previsÃµes sobre jogos futuros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_final(home, away, odd_h, odd_d, odd_a):\n",
    "    # 1. Buscar Stats Recentes\n",
    "    match_row = df_processed[(df_processed['HomeTeam'] == home) | (df_processed['AwayTeam'] == home)].tail(1)\n",
    "    if match_row.empty: return \"Equipa Home desconhecida\"\n",
    "    # (SimplificaÃ§Ã£o: usar Ãºltimas stats conhecidas)\n",
    "    # Nota: Num sistema de produÃ§Ã£o real, terias de recalcular as mÃ©dias com o jogo mais recente\n",
    "    \n",
    "    h_elo = elo_tracker.get(home, 1500)\n",
    "    a_elo = elo_tracker.get(away, 1500)\n",
    "    \n",
    "    # Criar input dictionary\n",
    "    input_data = {\n",
    "        'HomeElo': h_elo, 'AwayElo': a_elo, 'EloDiff': h_elo - a_elo,\n",
    "        'Prob_Home': 1/odd_h, 'Prob_Draw': 1/odd_d, 'Prob_Away': 1/odd_a\n",
    "    }\n",
    "    \n",
    "    # Preencher stats de forma (Home_Points, Away_Shots, etc.)\n",
    "    # Vamos buscar os valores da ultima linha conhecida no dataset\n",
    "    # (AtenÃ§Ã£o: Isto assume que o dataset estÃ¡ atualizado atÃ© Ã  semana passada)\n",
    "    \n",
    "    # Truque para preencher o resto das features com base nas Ãºltimas mÃ©dias conhecidas\n",
    "    h_row = df_processed[df_processed['HomeTeam'] == home].iloc[-1]\n",
    "    a_row = df_processed[df_processed['AwayTeam'] == away].iloc[-1]\n",
    "    \n",
    "    for feat in features:\n",
    "        if feat not in input_data:\n",
    "            if 'Home_' in feat:\n",
    "                input_data[feat] = h_row[feat] # Usa mÃ©dia histÃ³rica\n",
    "            elif 'Away_' in feat:\n",
    "                input_data[feat] = a_row[feat] # Usa mÃ©dia histÃ³rica\n",
    "\n",
    "    # Converter para DataFrame\n",
    "    X_input = pd.DataFrame([input_data])\n",
    "    X_input = X_input[features] # Garantir ordem\n",
    "    \n",
    "    # Prever\n",
    "    probs = best_model.predict_proba(X_input)[0]\n",
    "    \n",
    "    print(f\"\\nâš”ï¸ {home} vs {away}\")\n",
    "    print(f\"   Odds Mercado: {odd_h} | {odd_d} | {odd_a}\")\n",
    "    print(f\"ðŸ¤– IA PrevisÃ£o:\")\n",
    "    print(f\"   Casa:   {probs[2]*100:.1f}%\")\n",
    "    print(f\"   Empate: {probs[1]*100:.1f}%\")\n",
    "    print(f\"   Fora:   {probs[0]*100:.1f}%\")\n",
    "    \n",
    "    winner = np.argmax(probs)\n",
    "    labels = ['Fora', 'Empate', 'Casa']\n",
    "    print(f\"   >> Aposta Sugerida: {labels[winner]}\")\n",
    "\n",
    "\n",
    "predict_final('Aston Villa', 'Arsenal', 4.05, 3.45, 1.84)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
