{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "afd3bf03",
      "metadata": {},
      "source": [
        "# Premier League V4.5: Re-Optimizing for Draws\n",
        "\n",
        "A accuracy baixou porque mud√°mos as regras do jogo (pesos) mas mantivemos a estrat√©gia antiga.\n",
        "Nesta etapa, vamos correr o **Grid Search** novamente, mas desta vez informando o Grid Search de que os empates s√£o importantes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62edbbd4",
      "metadata": {},
      "source": [
        "Imports e Configura√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3950eca4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib # Para salvar o modelo\n",
        "import re\n",
        "import os\n",
        "import codecs\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14553427",
      "metadata": {},
      "source": [
        "## 1. Data Acquisition (Recolha de Dados)\n",
        "Vamos buscar dados reais do `football-data.co.uk`. Vamos carregar v√°rias temporadas consecutivas para que o modelo tenha hist√≥rico suficiente para aprender padr√µes.\n",
        "\n",
        "* **FTHG**: Full Time Home Goals\n",
        "* **FTAG**: Full Time Away Goals\n",
        "* **FTR**: Full Time Result (H=Home, D=Draw, A=Away)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27652b81",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CONFIGURA√á√ÉO ---\n",
        "DATA_FILE = 'premier_league_full.csv'\n",
        "XG_FILE = 'premier_league_xg_data.csv'\n",
        "START_YEAR = 2000\n",
        "END_YEAR = 2025\n",
        "\n",
        "# --- FUN√á√ÉO 1: Scraper Robusto (Understat) ---\n",
        "def scrape_understat_season(year):\n",
        "    print(f\"üï∑Ô∏è A recolher xG de {year}/{year+1}...\")\n",
        "    url = f\"https://understat.com/league/EPL/{year}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        match = re.search(r\"datesData\\s*=\\s*JSON\\.parse\\('(.*?)'\\)\", response.text)\n",
        "        if not match:\n",
        "            print(f\"‚ö†Ô∏è Sem dados para {year}\")\n",
        "            return pd.DataFrame()\n",
        "            \n",
        "        json_data = codecs.decode(match.group(1), 'unicode_escape')\n",
        "        data = json.loads(json_data)\n",
        "        \n",
        "        matches = []\n",
        "        for m in data:\n",
        "            if m['isResult']:\n",
        "                matches.append({\n",
        "                    'Date': m['datetime'][:10],\n",
        "                    'HomeTeam': m['h']['title'],\n",
        "                    'AwayTeam': m['a']['title'],\n",
        "                    'Home_xG': float(m['xG']['h']),\n",
        "                    'Away_xG': float(m['xG']['a'])\n",
        "                })\n",
        "        return pd.DataFrame(matches)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro no ano {year}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# --- FUN√á√ÉO 2: Carregar Dados Principais (Football-Data) ---\n",
        "def get_main_data(start, end):\n",
        "    if os.path.exists(DATA_FILE):\n",
        "        print(f\"üìÇ Carregando dados locais: {DATA_FILE}\")\n",
        "        df = pd.read_csv(DATA_FILE)\n",
        "        # Importante: N√£o converter data aqui ainda para controlar formato no main\n",
        "        return df\n",
        "    \n",
        "    print(\"üåê A descarregar dados do Football-Data...\")\n",
        "    dfs = []\n",
        "    base_url = \"https://www.football-data.co.uk/mmz4281/{}/{}.csv\"\n",
        "    for year in range(start, end + 1):\n",
        "        season = f\"{str(year)[-2:]}{str(year+1)[-2:]}\"\n",
        "        try:\n",
        "            df = pd.read_csv(base_url.format(season, \"E0\"))\n",
        "            # For√ßar convers√£o imediata para evitar problemas de mistura\n",
        "            df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
        "            dfs.append(df)\n",
        "        except: pass\n",
        "        \n",
        "    full_df = pd.concat(dfs, ignore_index=True).dropna(subset=['Date', 'FTR'])\n",
        "    full_df.to_csv(DATA_FILE, index=False)\n",
        "    return full_df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# --- FUN√á√ÉO 3: Limpeza de Nomes ---\n",
        "def clean_team_name(name):\n",
        "    name_map = {\n",
        "        'Manchester United': 'Man United', 'Manchester City': 'Man City',\n",
        "        'Newcastle United': 'Newcastle', 'West Ham United': 'West Ham', 'West Ham': 'West Ham',\n",
        "        'Wolverhampton Wanderers': 'Wolves', 'Brighton': 'Brighton',\n",
        "        'Leicester City': 'Leicester', 'Leeds United': 'Leeds',\n",
        "        'Tottenham Hotspur': 'Tottenham', 'Tottenham': 'Tottenham', \n",
        "        'Nottingham Forest': \"Nott'm Forest\", 'Sheffield United': 'Sheffield United', \n",
        "        'Luton': 'Luton', 'Brentford': 'Brentford', 'Bournemouth': 'Bournemouth',\n",
        "        'Ipswich Town': 'Ipswich', 'Hull City': 'Hull', 'Stoke City': 'Stoke',\n",
        "        'Swansea City': 'Swansea', 'Cardiff City': 'Cardiff',\n",
        "        'Huddersfield Town': 'Huddersfield', 'West Bromwich Albion': 'West Brom',\n",
        "        'Norwich City': 'Norwich', 'Queens Park Rangers': 'QPR'\n",
        "    }\n",
        "    return name_map.get(name, name)\n",
        "\n",
        "# ==========================================\n",
        "# üöÄ EXECU√á√ÉO E LIMPEZA (A PARTE CR√çTICA)\n",
        "# ==========================================\n",
        "\n",
        "# 1. Carregar Dados Principais\n",
        "df = get_main_data(START_YEAR, END_YEAR)\n",
        "\n",
        "# Limpeza de Datas e Duplicados no Dataset Principal\n",
        "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
        "df = df.dropna(subset=['Date'])\n",
        "# Remove duplicados exatos no ficheiro principal\n",
        "df = df.drop_duplicates(subset=['Date', 'HomeTeam', 'AwayTeam'])\n",
        "\n",
        "# 2. Carregar ou Sacar xG\n",
        "if os.path.exists(XG_FILE):\n",
        "    print(\"üìÇ Carregando xG local...\")\n",
        "    df_xg = pd.read_csv(XG_FILE)\n",
        "else:\n",
        "    print(\"üåê A iniciar scraping xG...\")\n",
        "    dfs_xg = [scrape_understat_season(y) for y in range(START_YEAR, END_YEAR)]\n",
        "    df_xg = pd.concat(dfs_xg, ignore_index=True)\n",
        "    df_xg['HomeTeam'] = df_xg['HomeTeam'].apply(clean_team_name)\n",
        "    df_xg['AwayTeam'] = df_xg['AwayTeam'].apply(clean_team_name)\n",
        "    df_xg.to_csv(XG_FILE, index=False)\n",
        "\n",
        "# 3. PREPARA√á√ÉO PARA MERGE\n",
        "df_xg['Date'] = pd.to_datetime(df_xg['Date']).dt.normalize()\n",
        "df['Date'] = df['Date'].dt.normalize()\n",
        "\n",
        "# --- CORRE√á√ÉO: Remover duplicados no xG ANTES do Merge ---\n",
        "print(f\"üìä Linhas xG antes da limpeza: {len(df_xg)}\")\n",
        "df_xg = df_xg.drop_duplicates(subset=['Date', 'HomeTeam', 'AwayTeam'], keep='first')\n",
        "print(f\"üìâ Linhas xG limpas: {len(df_xg)}\")\n",
        "\n",
        "# Aplicar limpeza de nomes\n",
        "df['HomeTeam'] = df['HomeTeam'].apply(clean_team_name)\n",
        "df['AwayTeam'] = df['AwayTeam'].apply(clean_team_name)\n",
        "df_xg['HomeTeam'] = df_xg['HomeTeam'].apply(clean_team_name)\n",
        "df_xg['AwayTeam'] = df_xg['AwayTeam'].apply(clean_team_name)\n",
        "\n",
        "# Remover colunas antigas de xG no DF principal\n",
        "cols_exclude = [c for c in df.columns if 'xG' in c]\n",
        "df_clean = df.drop(columns=cols_exclude)\n",
        "\n",
        "# 4. MERGE FINAL\n",
        "print(\"üîÑ A realizar o Merge...\")\n",
        "df_final = df_clean.merge(\n",
        "    df_xg[['Date', 'HomeTeam', 'AwayTeam', 'Home_xG', 'Away_xG']],\n",
        "    on=['Date', 'HomeTeam', 'AwayTeam'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 5. REMOVER FUTURO (Seguran√ßa contra erro de datas)\n",
        "hoje = pd.Timestamp.now().normalize()\n",
        "antes = len(df_final)\n",
        "df_final = df_final[df_final['Date'] <= hoje]\n",
        "print(f\"üìÖ Jogos removidos (futuro/datas erradas): {antes - len(df_final)}\")\n",
        "\n",
        "# Ordenar Cronologicamente\n",
        "df = df_final.sort_values(['Date', 'HomeTeam', 'AwayTeam']).reset_index(drop=True)\n",
        "\n",
        "# Estat√≠stica\n",
        "missing_count = df['Home_xG'].isna().sum()\n",
        "print(f\"‚úÖ Merge conclu√≠do! Jogos com xG: {len(df) - missing_count} / {len(df)}\")\n",
        "print(f\"üìâ Jogos sem xG (Preenchidos com 1.0): {missing_count}\")\n",
        "\n",
        "# Preencher vazios\n",
        "df = df.fillna({'Home_xG': 1.0, 'Away_xG': 1.0})\n",
        "\n",
        "print(\"üîç A verificar duplicados no final:\")\n",
        "display(df.tail(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a02a0a",
      "metadata": {},
      "source": [
        "## 2. Feature Engineering Completa (ELO + Stats + Odds)\n",
        "\n",
        "Aqui adicionamos as colunas B365H, B365D, B365A (Odds da Bet365)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f923a5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Feature Engineering Update]\n",
        "def feature_engineering(df):\n",
        "    print(\"‚öôÔ∏è Generating Features with Double Chance Logic...\")\n",
        "    df = df.copy()\n",
        "    \n",
        "    # --- 1. LEAGUE STANDINGS ---\n",
        "    df['Season'] = df['Date'].apply(lambda x: x.year if x.month > 7 else x.year - 1)\n",
        "    df = df.sort_values('Date')\n",
        "    \n",
        "    standings = {} \n",
        "    df['Home_Pts'] = 0; df['Away_Pts'] = 0\n",
        "    df['Home_Pos'] = 10; df['Away_Pos'] = 10\n",
        "    \n",
        "    for i, row in df.iterrows():\n",
        "        season = row['Season']\n",
        "        h, a, res = row['HomeTeam'], row['AwayTeam'], row['FTR']\n",
        "        if season not in standings: standings[season] = {}\n",
        "        if h not in standings[season]: standings[season][h] = 0\n",
        "        if a not in standings[season]: standings[season][a] = 0\n",
        "        \n",
        "        df.at[i, 'Home_Pts'] = standings[season][h]\n",
        "        df.at[i, 'Away_Pts'] = standings[season][a]\n",
        "        \n",
        "        teams_sorted = sorted(standings[season].items(), key=lambda x: x[1], reverse=True)\n",
        "        ranks = {t: r+1 for r, (t, p) in enumerate(teams_sorted)}\n",
        "        df.at[i, 'Home_Pos'] = ranks.get(h, 15)\n",
        "        df.at[i, 'Away_Pos'] = ranks.get(a, 15)\n",
        "        \n",
        "        pts_h = 3 if res == 'H' else 1 if res == 'D' else 0\n",
        "        pts_a = 3 if res == 'A' else 1 if res == 'D' else 0\n",
        "        standings[season][h] += pts_h\n",
        "        standings[season][a] += pts_a\n",
        "\n",
        "    df['PtsDiff'] = df['Home_Pts'] - df['Away_Pts']\n",
        "    df['PosDiff'] = df['Home_Pos'] - df['Away_Pos']\n",
        "\n",
        "    # --- 2. REFEREE BIAS ---\n",
        "    if 'Referee' in df.columns:\n",
        "        le_ref = LabelEncoder()\n",
        "        df['Referee'] = df['Referee'].fillna('Unknown')\n",
        "        df['Ref_ID'] = le_ref.fit_transform(df['Referee'])\n",
        "        ref_stats = df.groupby('Referee')[['HY', 'AY', 'HR', 'AR']].mean()\n",
        "        ref_stats['Ref_Avg_Cards'] = ref_stats['HY'] + ref_stats['AY'] + 2*(ref_stats['HR'] + ref_stats['AR'])\n",
        "        df = df.merge(ref_stats['Ref_Avg_Cards'], on='Referee', how='left')\n",
        "    else:\n",
        "        df['Ref_ID'] = 0\n",
        "        df['Ref_Avg_Cards'] = 3.5\n",
        "\n",
        "    # --- 3. ELO RATING ---\n",
        "    df['HomeElo'] = 1500.0; df['AwayElo'] = 1500.0\n",
        "    elo_dict = {}\n",
        "    k_factor = 20\n",
        "    \n",
        "    for i, row in df.iterrows():\n",
        "        h, a, res = row['HomeTeam'], row['AwayTeam'], row['FTR']\n",
        "        h_elo = elo_dict.get(h, 1500.0)\n",
        "        a_elo = elo_dict.get(a, 1500.0)\n",
        "        df.at[i, 'HomeElo'] = h_elo\n",
        "        df.at[i, 'AwayElo'] = a_elo\n",
        "        actual = 1 if res == 'H' else 0.5 if res == 'D' else 0\n",
        "        exp = 1 / (1 + 10**((a_elo - h_elo)/400))\n",
        "        update = k_factor * (actual - exp)\n",
        "        elo_dict[h] = h_elo + update\n",
        "        elo_dict[a] = a_elo - update\n",
        "    df['EloDiff'] = df['HomeElo'] - df['AwayElo']\n",
        "\n",
        "    # --- 4. ROLLING STATS ---\n",
        "    cols_to_avg = ['FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR', \n",
        "                   'Home_xG', 'Away_xG', 'Home_PPDA', 'Away_PPDA', 'Home_Deep', 'Away_Deep']\n",
        "    \n",
        "    cols_to_avg = [c for c in cols_to_avg if c in df.columns]\n",
        "    \n",
        "    rename_h = {'FTHG': 'Goals', 'FTAG': 'Conceded', 'HS': 'Shots', 'AS': 'ShotsConceded', \n",
        "                'HST': 'ShotsTarget', 'AST': 'STConceded', 'HC': 'Corners', 'AC': 'CornersConceded',\n",
        "                'HF': 'Fouls', 'AF': 'FoulsSuffered', 'HY': 'Yellows', 'AY': 'YellowsOpp', \n",
        "                'HR': 'Reds', 'AR': 'RedsOpp', 'Home_xG': 'xG_For', 'Away_xG': 'xG_Against',\n",
        "                'Home_PPDA': 'PPDA_For', 'Away_PPDA': 'PPDA_Allowed',\n",
        "                'Home_Deep': 'Deep_For', 'Away_Deep': 'Deep_Allowed'}\n",
        "                \n",
        "    rename_a = {'FTAG': 'Goals', 'FTHG': 'Conceded', 'AS': 'Shots', 'HS': 'ShotsConceded', \n",
        "                'AST': 'ShotsTarget', 'HST': 'STConceded', 'AC': 'Corners', 'HC': 'CornersConceded',\n",
        "                'AF': 'Fouls', 'HF': 'FoulsSuffered', 'AY': 'Yellows', 'HY': 'YellowsOpp',\n",
        "                'AR': 'Reds', 'HR': 'RedsOpp', 'Away_xG': 'xG_For', 'Home_xG': 'xG_Against',\n",
        "                'Away_PPDA': 'PPDA_For', 'Home_PPDA': 'PPDA_Allowed',\n",
        "                'Away_Deep': 'Deep_For', 'Home_Deep': 'Deep_Allowed'}\n",
        "    \n",
        "    home_stats = df[['Date', 'HomeTeam'] + cols_to_avg].rename(columns={'HomeTeam': 'Team'}).rename(columns=rename_h)\n",
        "    away_stats = df[['Date', 'AwayTeam'] + cols_to_avg].rename(columns={'AwayTeam': 'Team'}).rename(columns=rename_a)\n",
        "    all_stats = pd.concat([home_stats, away_stats]).sort_values(['Team', 'Date'])\n",
        "    \n",
        "    metrics = list(set(rename_h.values()))\n",
        "    metrics = [m for m in metrics if m in all_stats.columns]\n",
        "\n",
        "    for col in metrics:\n",
        "        all_stats[f'Avg_{col}_L5'] = all_stats.groupby('Team')[col].transform(lambda x: x.shift(1).rolling(5, min_periods=3).mean()).fillna(0)\n",
        "    \n",
        "    feature_cols = ['Date', 'Team'] + [c for c in all_stats.columns if 'Avg_' in c]\n",
        "    df = df.merge(all_stats[feature_cols], left_on=['Date', 'HomeTeam'], right_on=['Date', 'Team'], how='left')\n",
        "    df = df.rename(columns={c: f'Home_{c}' for c in feature_cols if c not in ['Date', 'Team']}).drop(columns=['Team'])\n",
        "    df = df.merge(all_stats[feature_cols], left_on=['Date', 'AwayTeam'], right_on=['Date', 'Team'], how='left')\n",
        "    df = df.rename(columns={c: f'Away_{c}' for c in feature_cols if c not in ['Date', 'Team']}).drop(columns=['Team'])\n",
        "\n",
        "    # --- 5. CLEANUP & FEATURES FINAIS ---\n",
        "    df['Rest_Home'] = df.groupby('HomeTeam')['Date'].diff().dt.days.fillna(7).clip(upper=15)\n",
        "    df['Rest_Away'] = df.groupby('AwayTeam')['Date'].diff().dt.days.fillna(7).clip(upper=15)\n",
        "    \n",
        "    # === NEW: IMPLIED ODDS INCLUDING DOUBLE CHANCE ===\n",
        "    if 'B365H' in df.columns:\n",
        "        # Standard Implied Probabilities (Inverse of Odds)\n",
        "        df['Imp_Home'] = 1 / df['B365H']\n",
        "        df['Imp_Draw'] = 1 / df['B365D']\n",
        "        df['Imp_Away'] = 1 / df['B365A']\n",
        "        \n",
        "        # Synthetic Double Chance Implied Probabilities (Estimation for training)\n",
        "        # This gives the model a sense of \"Safety\" for a result\n",
        "        # 1X (Home or Draw) prob is roughly Sum of Prob(H) + Prob(D)\n",
        "        df['Imp_1X'] = df['Imp_Home'] + df['Imp_Draw']\n",
        "        df['Imp_X2'] = df['Imp_Draw'] + df['Imp_Away']\n",
        "        df['Imp_12'] = df['Imp_Home'] + df['Imp_Away'] # Home or Away (No Draw)\n",
        "\n",
        "    # --- 6. DIFFS T√ÅTICOS ---\n",
        "    if 'Home_Avg_Deep_For_L5' in df.columns:\n",
        "        df['Deep_Advantage'] = df['Home_Avg_Deep_For_L5'] - df['Away_Avg_Deep_For_L5']\n",
        "        df['PPDA_Diff'] = df['Home_Avg_PPDA_For_L5'] - df['Away_Avg_PPDA_For_L5']\n",
        "\n",
        "    features_needed = [\n",
        "        'HomeElo', 'AwayElo', 'EloDiff', \n",
        "        'Rest_Home', 'Rest_Away', \n",
        "        'Imp_Home', 'Imp_Draw', 'Imp_Away',\n",
        "        'Imp_1X', 'Imp_X2', 'Imp_12', # <--- ADDED NEW FEATURES HERE\n",
        "        'Home_Pts', 'Away_Pts', 'Home_Pos', 'Away_Pos', 'PtsDiff', 'PosDiff',\n",
        "        'Ref_ID', 'Ref_Avg_Cards'\n",
        "    ]\n",
        "    \n",
        "    if 'Deep_Advantage' in df.columns:\n",
        "        features_needed += ['Deep_Advantage', 'PPDA_Diff']\n",
        "\n",
        "    features_needed += [c for c in df.columns if 'Home_Avg_' in c or 'Away_Avg_' in c]\n",
        "    \n",
        "    existing_features = [f for f in features_needed if f in df.columns]\n",
        "    \n",
        "    df_clean = df.dropna(subset=['FTR', 'Imp_Home']).copy()\n",
        "    df_clean[existing_features] = df_clean[existing_features].fillna(0)\n",
        "    \n",
        "    return df_clean, existing_features, elo_dict\n",
        "\n",
        "# Re-run feature engineering\n",
        "df_ready, features, current_elos = feature_engineering(df)\n",
        "print(f\"‚úÖ Features updated. Total features: {len(features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f5a89c",
      "metadata": {},
      "source": [
        "## 3. Prepara√ß√£o e Treino do Modelo\n",
        "Treino Intensivo: Grid Search (Hyperparameter Tuning) Aqui √© onde \"apertamos\" o modelo. Vamos testar v√°rias combina√ß√µes. Nota: Isto pode demorar 2 ou 3 minutos a correr."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c2e9837",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Training & Evaluation]\n",
        "\n",
        "# 1. Prepare Data\n",
        "target = 'Target'\n",
        "le = LabelEncoder()\n",
        "df_ready['Target'] = le.fit_transform(df_ready['FTR']) # 0=Away, 1=Draw, 2=Home\n",
        "\n",
        "# Split 80/20 (Chronological split to preserve time order)\n",
        "split_index = int(len(df_ready) * 0.80)\n",
        "train = df_ready.iloc[:split_index]\n",
        "test = df_ready.iloc[split_index:]\n",
        "\n",
        "X_train, y_train = train[features], train['Target']\n",
        "X_test, y_test = test[features], test['Target']\n",
        "\n",
        "print(f\"üèãÔ∏è Training on {len(X_train)} games...\")\n",
        "\n",
        "# --- MODEL 1: MULTI-CLASS (O C√©rebro Geral) ---\n",
        "# Prever as probabilidades exatas de Home/Draw/Away\n",
        "print(\"   ... Fitting Multi-Class Model (XGBoost)\")\n",
        "model_multi = xgb.XGBClassifier(\n",
        "    n_estimators=300,        \n",
        "    learning_rate=0.03,       \n",
        "    max_depth=4,              \n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective='multi:softprob',\n",
        "    random_state=42\n",
        ")\n",
        "# Damos um ligeiro peso extra aos empates para o modelo n√£o os ignorar\n",
        "sample_weights = np.ones(len(y_train))\n",
        "draw_code = le.transform(['D'])[0]\n",
        "sample_weights[y_train == draw_code] = 1.20 \n",
        "model_multi.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "# --- MODEL 2: BINARY SNIPER (Home Win vs Rest) ---\n",
        "# Especialista em dizer se a Casa ganha mesmo\n",
        "print(\"   ... Fitting Binary Sniper (Home Win Only)\")\n",
        "y_train_win = (y_train == 2).astype(int) \n",
        "y_test_win = (y_test == 2).astype(int)\n",
        "\n",
        "model_sniper = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.02, \n",
        "    max_depth=4,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "model_sniper.fit(X_train, y_train_win)\n",
        "\n",
        "# --- MODEL 3: BINARY SHIELD (Double Chance 1X vs Away) ---\n",
        "# Especialista em dizer \"N√£o Perde\" (Casa ou Empate)\n",
        "# Se Target != 0 (Away), ent√£o √© 1 (Draw) ou 2 (Home), logo √© 1X.\n",
        "print(\"   ... Fitting Binary Shield (1X - Double Chance)\")\n",
        "y_train_1x = (y_train != 0).astype(int)\n",
        "y_test_1x = (y_test != 0).astype(int)\n",
        "\n",
        "model_shield = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.02, \n",
        "    max_depth=4,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "model_shield.fit(X_train, y_train_1x)\n",
        "\n",
        "print(\"üèÜ All Models Trained Successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27e62128",
      "metadata": {},
      "source": [
        "## Gr√°ficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf1432f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Visualization]\n",
        "print(\"\\nüìä EVALUATION REPORT\")\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# 1. Multi-Class Evaluation\n",
        "preds_multi = model_multi.predict(X_test)\n",
        "acc_multi = accuracy_score(y_test, preds_multi)\n",
        "cm_multi = confusion_matrix(y_test, preds_multi)\n",
        "labels_multi = ['Away', 'Draw', 'Home']\n",
        "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=labels_multi, yticklabels=labels_multi, ax=axes[0])\n",
        "axes[0].set_title(f'General Model (Acc: {acc_multi:.1%})')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "\n",
        "# 2. Sniper Evaluation (Win?)\n",
        "preds_sniper = model_sniper.predict(X_test)\n",
        "acc_sniper = accuracy_score(y_test_win, preds_sniper)\n",
        "cm_sniper = confusion_matrix(y_test_win, preds_sniper)\n",
        "sns.heatmap(cm_sniper, annot=True, fmt='d', cmap='Greens', \n",
        "            xticklabels=['Not Win', 'Home Win'], yticklabels=['Not Win', 'Home Win'], ax=axes[1])\n",
        "axes[1].set_title(f'Sniper Model (Win Only) (Acc: {acc_sniper:.1%})')\n",
        "\n",
        "# 3. Shield Evaluation (1X?)\n",
        "preds_shield = model_shield.predict(X_test)\n",
        "acc_shield = accuracy_score(y_test_1x, preds_shield)\n",
        "cm_shield = confusion_matrix(y_test_1x, preds_shield)\n",
        "sns.heatmap(cm_shield, annot=True, fmt='d', cmap='Oranges', \n",
        "            xticklabels=['Away Win', '1X (Home/Draw)'], yticklabels=['Away Win', '1X (Home/Draw)'], ax=axes[2])\n",
        "axes[2].set_title(f'Shield Model (1X) (Acc: {acc_shield:.1%})')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1c0479",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Feature Importance]\n",
        "feature_imp = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': model_multi.feature_importances_\n",
        "}).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"üìã TOP FEATURES (General Model):\")\n",
        "feature_imp['Importance %'] = (feature_imp['Importance'] * 100).round(2)\n",
        "display(feature_imp[['Feature', 'Importance %']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7176fed1",
      "metadata": {},
      "source": [
        "## 4. Aplica√ß√£o na \"Vida Real\"\n",
        "Aqui est√° a fun√ß√£o final. Ela usa o dicion√°rio `current_elo` (que cont√©m os valores mais recentes ap√≥s o √∫ltimo jogo do dataset) para fazer previs√µes sobre jogos futuros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae7c1481",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Prediction Function v3.0]\n",
        "def predict_match_advanced(date_str, home_team, away_team, \n",
        "                           odd_h, odd_d, odd_a, \n",
        "                           odd_1x=None, odd_12=None, odd_x2=None):\n",
        "    \n",
        "    match_date = pd.to_datetime(date_str)\n",
        "    print(f\"\\nüîÆ ADVANCED PREDICTION: {home_team} vs {away_team} ({date_str})\")\n",
        "    print(\"=\" * 65)\n",
        "    \n",
        "    # --- 1. PREPARE INPUT DATA ---\n",
        "    past_data = df_ready[df_ready['Date'] < match_date].copy()\n",
        "    if past_data.empty:\n",
        "        print(\"‚ö†Ô∏è Error: No historical data available.\")\n",
        "        return\n",
        "\n",
        "    # Helper: Days since last game\n",
        "    def get_days_since_last(team):\n",
        "        team_games = past_data[(past_data['HomeTeam'] == team) | (past_data['AwayTeam'] == team)]\n",
        "        if team_games.empty: return 7\n",
        "        return min(max((match_date - team_games.iloc[-1]['Date']).days, 3), 15)\n",
        "\n",
        "    input_data = {}\n",
        "    \n",
        "    # A) ELO & Rest\n",
        "    h_elo = current_elos.get(home_team, 1500)\n",
        "    a_elo = current_elos.get(away_team, 1500)\n",
        "    input_data['HomeElo'] = h_elo\n",
        "    input_data['AwayElo'] = a_elo\n",
        "    input_data['EloDiff'] = h_elo - a_elo\n",
        "    input_data['Rest_Home'] = get_days_since_last(home_team)\n",
        "    input_data['Rest_Away'] = get_days_since_last(away_team)\n",
        "    \n",
        "    # B) Odds Input (Features)\n",
        "    input_data['Imp_Home'] = 1/odd_h\n",
        "    input_data['Imp_Draw'] = 1/odd_d\n",
        "    input_data['Imp_Away'] = 1/odd_a\n",
        "    \n",
        "    # Mathematical Fallbacks for DC if not provided\n",
        "    input_data['Imp_1X'] = 1/odd_1x if odd_1x else (1/odd_h + 1/odd_d)\n",
        "    input_data['Imp_X2'] = 1/odd_x2 if odd_x2 else (1/odd_d + 1/odd_a)\n",
        "    input_data['Imp_12'] = 1/odd_12 if odd_12 else (1/odd_h + 1/odd_a)\n",
        "    \n",
        "    # C) Historical Stats (L5)\n",
        "    def fill_stats(team, prefix_h, prefix_a):\n",
        "        games = past_data[(past_data['HomeTeam'] == team) | (past_data['AwayTeam'] == team)]\n",
        "        if games.empty: return\n",
        "        last = games.iloc[-1]\n",
        "        for f in features:\n",
        "            if prefix_h in f: \n",
        "                clean = f.replace(prefix_h, \"\")\n",
        "                val = last[f\"Home_{clean}\"] if last['HomeTeam'] == team else last.get(f\"Away_{clean}\", 0)\n",
        "                input_data[f] = val\n",
        "            elif prefix_a in f:\n",
        "                clean = f.replace(prefix_a, \"\")\n",
        "                val = last[f\"Home_{clean}\"] if last['HomeTeam'] == team else last.get(f\"Away_{clean}\", 0)\n",
        "                input_data[f] = val\n",
        "\n",
        "    fill_stats(home_team, \"Home_\", \"XX_IGNORE_XX\")\n",
        "    fill_stats(away_team, \"XX_IGNORE_XX\", \"Away_\")\n",
        "\n",
        "    # D) Manual Diffs\n",
        "    if 'Deep_Advantage' in features:\n",
        "        input_data['Deep_Advantage'] = input_data.get('Home_Avg_Deep_For_L5', 0) - input_data.get('Away_Avg_Deep_For_L5', 0)\n",
        "    if 'PPDA_Diff' in features:\n",
        "        input_data['PPDA_Diff'] = input_data.get('Home_Avg_PPDA_For_L5', 0) - input_data.get('Away_Avg_PPDA_For_L5', 0)\n",
        "\n",
        "    # Fill NaNs\n",
        "    for f in features: \n",
        "        if f not in input_data: input_data[f] = df_ready[f].mean()\n",
        "\n",
        "    # --- 2. EXECUTE MODELS ---\n",
        "    X_new = pd.DataFrame([input_data])[features]\n",
        "    \n",
        "    # Model 1: General (Odds Justas)\n",
        "    probs = model_multi.predict_proba(X_new)[0] # [Away, Draw, Home]\n",
        "    prob_a, prob_d, prob_h = probs[0], probs[1], probs[2]\n",
        "    \n",
        "    # Model 2: Sniper (Home Win Confidence)\n",
        "    conf_win = model_sniper.predict_proba(X_new)[0][1] # Prob of Class 1 (Win)\n",
        "    \n",
        "    # Model 3: Shield (1X Confidence)\n",
        "    conf_1x = model_shield.predict_proba(X_new)[0][1] # Prob of Class 1 (1X)\n",
        "\n",
        "    # Derived Probs for DC (Combinando Math + Modelos Espec√≠ficos)\n",
        "    prob_1x_final = ( (prob_h + prob_d) + conf_1x ) / 2\n",
        "    prob_x2_final = prob_d + prob_a\n",
        "    prob_12_final = prob_h + prob_a\n",
        "\n",
        "    # --- 3. REPORTING ---\n",
        "    print(f\"üìä PROBABILITIES (AI Consensus):\")\n",
        "    print(f\"   üè† Home Win: {prob_h:.1%}  (Sniper Confidence: {conf_win:.1%})\")\n",
        "    print(f\"   ü§ù Draw:     {prob_d:.1%}\")\n",
        "    print(f\"   ‚úàÔ∏è Away Win: {prob_a:.1%}\")\n",
        "    print(\"-\" * 65)\n",
        "\n",
        "    # Store opportunities to sort best at the end\n",
        "    opportunities = []\n",
        "\n",
        "    def check_value(name, odd, prob, type_bet):\n",
        "        if not odd or odd <= 1: return\n",
        "        fair = 1/prob if prob > 0 else 99\n",
        "        is_value = odd > fair\n",
        "        \n",
        "        # Calculate EV (Expected Value)\n",
        "        ev = (prob * odd) - 1\n",
        "        \n",
        "        status = \"üíé VALUE\" if is_value else \"Bad Price\"\n",
        "        print(f\"   ‚Ä¢ {name:<15} | Odd: {odd:.2f} | AI Fair: {fair:.2f} | {status}\")\n",
        "        \n",
        "        # Add to list for final decision\n",
        "        opportunities.append({\n",
        "            \"name\": name,\n",
        "            \"odd\": odd,\n",
        "            \"prob\": prob,\n",
        "            \"ev\": ev,\n",
        "            \"is_value\": is_value,\n",
        "            \"type\": type_bet\n",
        "        })\n",
        "\n",
        "    print(\"üí∞ MARKET ANALYSIS:\")\n",
        "    check_value(f\"Win {home_team}\", odd_h, prob_h, \"HOME\")\n",
        "    check_value(\"Draw\", odd_d, prob_d, \"DRAW\")\n",
        "    check_value(f\"Win {away_team}\", odd_a, prob_a, \"AWAY\")\n",
        "    print(\"   . . .\")\n",
        "    \n",
        "    if odd_1x: check_value(\"DC 1X\", odd_1x, prob_1x_final, \"1X\")\n",
        "    if odd_x2: check_value(\"DC X2\", odd_x2, prob_x2_final, \"X2\")\n",
        "    if odd_12: check_value(\"DC 12 (No Draw)\", odd_12, prob_12_final, \"12\") # <--- NOVO\n",
        "\n",
        "    print(\"-\" * 65)\n",
        "    print(\"üß† FINAL VERDICT:\")\n",
        "    \n",
        "    # 1. Sort by Expected Value (EV) descending\n",
        "    opportunities.sort(key=lambda x: x['ev'], reverse=True)\n",
        "    best_op = opportunities[0]\n",
        "    \n",
        "    # 2. Logic for Recommendation\n",
        "    if best_op['is_value'] and best_op['ev'] > 0.05:\n",
        "        # Strong Value Found\n",
        "        print(f\"üöÄ BEST BET: {best_op['name']} (Value Bet!)\")\n",
        "        print(f\"   Reason: The odd {best_op['odd']} is higher than fair price {1/best_op['prob']:.2f}\")\n",
        "    \n",
        "    elif best_op['is_value']:\n",
        "        # Small Value Found\n",
        "        print(f\"‚úÖ GOOD OPTION: {best_op['name']} (Small Value)\")\n",
        "        print(f\"   Reason: Marginal value found. Good for accas.\")\n",
        "        \n",
        "    else:\n",
        "        # No Value Found -> Recommend based on pure Probability\n",
        "        # Sort by Probability instead of EV\n",
        "        opportunities.sort(key=lambda x: x['prob'], reverse=True)\n",
        "        safest_op = opportunities[0]\n",
        "        \n",
        "        print(f\"ü§∑ NO VALUE FOUND (Odds are tight).\")\n",
        "        print(f\"üëâ SAFEST PICK: {safest_op['name']} (Prob: {safest_op['prob']:.1%})\")\n",
        "        print(f\"   ‚ö†Ô∏è Warning: Market price ({safest_op['odd']}) is slightly below fair odds.\")\n",
        "\n",
        "# Example Usage:\n",
        "predict_match_advanced('2025-12-08', 'Wolves', 'Man United', \n",
        "                       odd_h=4.45, odd_d=3.93, odd_a=1.67, \n",
        "                       odd_1x=2.02, odd_12=1.22, odd_x2=1.18)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
