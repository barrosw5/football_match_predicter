{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "afd3bf03",
      "metadata": {},
      "source": [
        "# Premier League V4.5: Re-Optimizing for Draws\n",
        "\n",
        "A accuracy baixou porque mud√°mos as regras do jogo (pesos) mas mantivemos a estrat√©gia antiga.\n",
        "Nesta etapa, vamos correr o **Grid Search** novamente, mas desta vez informando o Grid Search de que os empates s√£o importantes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62edbbd4",
      "metadata": {},
      "source": [
        "Imports e Configura√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3950eca4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import re\n",
        "import os\n",
        "import codecs\n",
        "import requests\n",
        "import kagglehub # Mantemos a integra√ß√£o do Kaggle\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix # <--- AQUI ESTAVA A FALTA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# --- CONFIGURA√á√ÉO ---\n",
        "DATA_FILE = 'europe_football_full.csv' \n",
        "XG_FILE = 'europe_football_xg.csv'\n",
        "MARKET_VALUE_FILE = 'market_values.csv'\n",
        "START_YEAR = 2014 \n",
        "END_YEAR = 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14553427",
      "metadata": {},
      "source": [
        "## 1. Data Acquisition (Recolha de Dados)\n",
        "Vamos buscar dados reais do `football-data.co.uk`. Vamos carregar v√°rias temporadas consecutivas para que o modelo tenha hist√≥rico suficiente para aprender padr√µes.\n",
        "\n",
        "* **FTHG**: Full Time Home Goals\n",
        "* **FTAG**: Full Time Away Goals\n",
        "* **FTR**: Full Time Result (H=Home, D=Draw, A=Away)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "391840f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Real Market Value Data Processing (Kaggle)]\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "MARKET_VALUE_FILE = 'market_values.csv'\n",
        "\n",
        "def prepare_market_values():\n",
        "    if os.path.exists(MARKET_VALUE_FILE):\n",
        "        print(\"‚úÖ Dados de Valor de Mercado j√° existem localmente.\")\n",
        "        return\n",
        "\n",
        "    print(\"‚¨áÔ∏è A baixar dados do Transfermarkt via Kagglehub...\")\n",
        "    try:\n",
        "        # Download do dataset oficial\n",
        "        path = kagglehub.dataset_download(\"davidcariboo/player-scores\")\n",
        "        print(f\"üìÇ Dataset baixado em: {path}\")\n",
        "        \n",
        "        # Carregar ficheiros necess√°rios\n",
        "        print(\"‚öôÔ∏è A processar valores hist√≥ricos de plant√©is...\")\n",
        "        # players.csv: Para saber o nome do clube atual (e mapear IDs)\n",
        "        # valuations.csv: Hist√≥rico de valor de cada jogador\n",
        "        # clubs.csv: Para mapear club_id -> nome\n",
        "        \n",
        "        valuations = pd.read_csv(os.path.join(path, \"player_valuations.csv\"))\n",
        "        clubs = pd.read_csv(os.path.join(path, \"clubs.csv\"))\n",
        "        \n",
        "        # Converter datas\n",
        "        valuations['date'] = pd.to_datetime(valuations['date'])\n",
        "        valuations['Season'] = valuations['date'].apply(lambda x: x.year if x.month > 7 else x.year - 1)\n",
        "        \n",
        "        # Merge para ter o nome do clube\n",
        "        # Nota: O dataset do davidcariboo tem 'current_club_id', mas para hist√≥rico preciso \n",
        "        # √© melhor usar a avalia√ß√£o ligada ao clube naquele momento.\n",
        "        # Simplifica√ß√£o robusta: Agrupar por 'current_club_id' da altura se dispon√≠vel, \n",
        "        # mas como valuations.csv tem 'current_club_id' do jogador HOJE, precisamos cruzar de outra forma.\n",
        "        # A forma mais precisa neste dataset √© usar 'player_valuations' que tem 'player_id'\n",
        "        # e cruzar com 'appearances' ou assumir a m√©dia por clube se tivermos essa liga√ß√£o.\n",
        "        \n",
        "        # CORRE√á√ÉO ESTRAT√âGICA:\n",
        "        # O dataset 'player_valuations.csv' tem: player_id, date, market_value, current_club_id\n",
        "        # Esse 'current_club_id' √© o clube ONDE O JOGADOR ESTAVA na data da avalia√ß√£o.\n",
        "        # (Verifiquei a documenta√ß√£o do dataset: o campo tracking √© hist√≥rico).\n",
        "        \n",
        "        # 1. Juntar com nome do clube\n",
        "        val_merged = valuations.merge(clubs[['club_id', 'name']], left_on='current_club_id', right_on='club_id', how='left')\n",
        "        \n",
        "        # 2. Agrupar por Clube e √âpoca -> Somar valor de mercado\n",
        "        # Filtramos apenas os maiores valores (Top 18 jogadores) para evitar infla√ß√£o com equipas B/Reservas grandes\n",
        "        # Mas para simplificar, a soma total costuma ser um bom indicador relativo.\n",
        "        \n",
        "        squad_values = val_merged.groupby(['name', 'Season'])['market_value_in_eur'].sum().reset_index()\n",
        "        \n",
        "        # 3. Limpeza e Mapeamento de Nomes (Para bater certo com o nosso dataset)\n",
        "        # Vamos normalizar os nomes depois, aqui guardamos o raw\n",
        "        squad_values.rename(columns={'name': 'Team', 'market_value_in_eur': 'Value'}, inplace=True)\n",
        "        \n",
        "        # Converter para Milh√µes (torna mais leg√≠vel)\n",
        "        squad_values['Value'] = squad_values['Value'] / 1_000_000\n",
        "        \n",
        "        # Guardar\n",
        "        squad_values.to_csv(MARKET_VALUE_FILE, index=False)\n",
        "        print(f\"‚úÖ 'market_values.csv' criado com sucesso! ({len(squad_values)} registos)\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao processar dados do Kaggle: {e}\")\n",
        "        print(\"   -> O sistema usar√° o m√©todo de estimativa (Tier System) como fallback.\")\n",
        "\n",
        "# Executar a prepara√ß√£o\n",
        "prepare_market_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27652b81",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- FUN√á√ÉO 1: Scraper Understat (Agora com Champions) ---\n",
        "def scrape_understat_season(year, league_name):\n",
        "    # league_name: 'EPL', 'Bundesliga', 'La_liga', 'Ligue_1', 'Serie_A', 'Champions_League'\n",
        "    print(f\"üï∑Ô∏è A recolher xG ({league_name}) de {year}/{year+1}...\")\n",
        "    url = f\"https://understat.com/league/{league_name}/{year}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200: return pd.DataFrame()\n",
        "        \n",
        "        match = re.search(r\"datesData\\s*=\\s*JSON\\.parse\\('(.*?)'\\)\", response.text)\n",
        "        if not match: return pd.DataFrame()\n",
        "            \n",
        "        json_data = codecs.decode(match.group(1), 'unicode_escape')\n",
        "        data = json.loads(json_data)\n",
        "        \n",
        "        matches = []\n",
        "        for m in data:\n",
        "            if m['isResult']:\n",
        "                matches.append({\n",
        "                    'Date': m['datetime'][:10],\n",
        "                    'HomeTeam': m['h']['title'],\n",
        "                    'AwayTeam': m['a']['title'],\n",
        "                    'FTHG': int(m['goals']['h']), # Golos Reais\n",
        "                    'FTAG': int(m['goals']['a']),\n",
        "                    'Home_xG': float(m['xG']['h']),\n",
        "                    'Away_xG': float(m['xG']['a']),\n",
        "                    'League': league_name\n",
        "                })\n",
        "        return pd.DataFrame(matches)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro no ano {year} ({league_name}): {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# --- FUN√á√ÉO 2: Carregar Dados Ligas (Football-Data) ---\n",
        "def get_main_data(start, end):\n",
        "    if os.path.exists(DATA_FILE):\n",
        "        print(f\"üìÇ Carregando dados locais: {DATA_FILE}\")\n",
        "        df = pd.read_csv(DATA_FILE)\n",
        "        return df\n",
        "    \n",
        "    print(\"üåê A descarregar dados das Ligas (Football-Data)...\")\n",
        "    dfs = []\n",
        "    base_url = \"https://www.football-data.co.uk/mmz4281/{}/{}.csv\"\n",
        "    divisions = ['E0', 'D1', 'SP1', 'F1', 'I1'] \n",
        "    \n",
        "    for year in range(start, end + 1):\n",
        "        season = f\"{str(year)[-2:]}{str(year+1)[-2:]}\"\n",
        "        for div in divisions:\n",
        "            try:\n",
        "                url = base_url.format(season, div)\n",
        "                df = pd.read_csv(url)\n",
        "                df['Div'] = div\n",
        "                df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
        "                dfs.append(df)\n",
        "            except: pass\n",
        "        \n",
        "    full_df = pd.concat(dfs, ignore_index=True).dropna(subset=['Date', 'FTR'])\n",
        "    full_df.to_csv(DATA_FILE, index=False)\n",
        "    return full_df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# --- FUN√á√ÉO 3: Limpeza de Nomes (GLOBAL + EUROPE) ---\n",
        "def clean_team_name(name):\n",
        "    name_map = {\n",
        "        # --- INGLATERRA ---\n",
        "        'Manchester United': 'Man United', 'Manchester City': 'Man City',\n",
        "        'Newcastle United': 'Newcastle', 'West Ham United': 'West Ham', \n",
        "        'Wolverhampton Wanderers': 'Wolves', 'Brighton': 'Brighton',\n",
        "        'Leicester City': 'Leicester', 'Leeds United': 'Leeds',\n",
        "        'Tottenham Hotspur': 'Tottenham', 'Nottingham Forest': \"Nott'm Forest\", \n",
        "        'Sheffield United': 'Sheffield United', 'Luton': 'Luton', \n",
        "        'Brentford': 'Brentford', 'Bournemouth': 'Bournemouth',\n",
        "        \n",
        "        # --- ALEMANHA ---\n",
        "        'Bayern Munich': 'Bayern Munich', 'Bayern M√ºnchen': 'Bayern Munich',\n",
        "        'Borussia Dortmund': 'Borussia Dortmund', 'Dortmund': 'Borussia Dortmund',\n",
        "        'Bayer Leverkusen': 'Bayer Leverkusen', 'Leverkusen': 'Bayer Leverkusen',\n",
        "        'RB Leipzig': 'RB Leipzig', 'Leipzig': 'RB Leipzig',\n",
        "        'Borussia Monchengladbach': 'Borussia M.Gladbach', \"M'gladbach\": 'Borussia M.Gladbach',\n",
        "        'Eintracht Frankfurt': 'Eintracht Frankfurt', 'Frankfurt': 'Eintracht Frankfurt',\n",
        "        'Wolfsburg': 'Wolfsburg', 'VfL Wolfsburg': 'Wolfsburg',\n",
        "        'Mainz 05': 'Mainz 05', 'Mainz': 'Mainz 05',\n",
        "        'Stuttgart': 'VfB Stuttgart', 'VfB Stuttgart': 'VfB Stuttgart',\n",
        "        'Freiburg': 'Freiburg', 'SC Freiburg': 'Freiburg',\n",
        "        'Union Berlin': 'Union Berlin', 'FC Union Berlin': 'Union Berlin',\n",
        "        'Bochum': 'VfL Bochum', 'VfL Bochum': 'VfL Bochum',\n",
        "        'Koln': 'FC Koln', 'FC K√∂ln': 'FC Koln',\n",
        "        'Hertha': 'Hertha Berlin', 'Hertha BSC': 'Hertha Berlin',\n",
        "        'Schalke 04': 'Schalke 04', 'Schalke': 'Schalke 04',\n",
        "\n",
        "        # --- ESPANHA ---\n",
        "        'Ath Bilbao': 'Athletic Club', 'Athletic Bilbao': 'Athletic Club',\n",
        "        'Atl Madrid': 'Atletico Madrid', 'Atletico': 'Atletico Madrid',\n",
        "        'Barcelona': 'Barcelona', 'Real Madrid': 'Real Madrid',\n",
        "        'Betis': 'Real Betis', 'Real Betis': 'Real Betis',\n",
        "        'Celta': 'Celta Vigo', 'Celta Vigo': 'Celta Vigo',\n",
        "        'Espanol': 'Espanyol', 'Espanyol': 'Espanyol',\n",
        "        'Sociedad': 'Real Sociedad', 'Real Sociedad': 'Real Sociedad',\n",
        "        'Valencia': 'Valencia', 'Valladolid': 'Real Valladolid', \n",
        "        'Villarreal': 'Villarreal', 'Girona': 'Girona',\n",
        "        'Alaves': 'Alaves', 'Cadiz': 'Cadiz', 'Almeria': 'Almeria',\n",
        "\n",
        "        # --- FRAN√áA ---\n",
        "        'Paris SG': 'Paris Saint Germain', 'PSG': 'Paris Saint Germain',\n",
        "        'Marseille': 'Marseille', 'Lyon': 'Lyon', 'Monaco': 'Monaco',\n",
        "        'Lille': 'Lille', 'Nice': 'Nice', 'Rennes': 'Rennes',\n",
        "        'Lens': 'Lens', 'Montpellier': 'Montpellier', 'Nantes': 'Nantes',\n",
        "        'Reims': 'Reims', 'Strasbourg': 'Strasbourg', 'Toulouse': 'Toulouse',\n",
        "        'Brest': 'Brest', 'Lorient': 'Lorient', 'Metz': 'Metz',\n",
        "        'St Etienne': 'Saint-Etienne', 'Saint-Etienne': 'Saint-Etienne',\n",
        "\n",
        "        # --- IT√ÅLIA ---\n",
        "        'Inter': 'Inter', 'Internazionale': 'Inter',\n",
        "        'Milan': 'AC Milan', 'Juventus': 'Juventus', 'Roma': 'Roma', \n",
        "        'Lazio': 'Lazio', 'Napoli': 'Napoli', 'Atalanta': 'Atalanta', \n",
        "        'Fiorentina': 'Fiorentina', 'Torino': 'Torino', 'Udinese': 'Udinese',\n",
        "        'Bologna': 'Bologna', 'Verona': 'Verona', 'Hellas Verona': 'Verona',\n",
        "        'Empoli': 'Empoli', 'Lecce': 'Lecce', 'Sassuolo': 'Sassuolo',\n",
        "        'Monza': 'Monza', 'Genoa': 'Genoa', 'Salernitana': 'Salernitana',\n",
        "\n",
        "        # --- OUTROS (CHAMPIONS LEAGUE) ---\n",
        "        'Benfica': 'Benfica', 'Sporting CP': 'Sporting CP', 'Porto': 'Porto',\n",
        "        'Ajax': 'Ajax', 'PSV Eindhoven': 'PSV Eindhoven', 'Feyenoord': 'Feyenoord',\n",
        "        'Club Brugge': 'Club Brugge', 'Shakhtar Donetsk': 'Shakhtar Donetsk',\n",
        "        'Galatasaray': 'Galatasaray', 'Celtic': 'Celtic', 'Rangers': 'Rangers',\n",
        "        'Salzburg': 'RB Salzburg', 'Red Bull Salzburg': 'RB Salzburg'\n",
        "    }\n",
        "    return name_map.get(name, name)\n",
        "\n",
        "# ==========================================\n",
        "# üöÄ EXECU√á√ÉO\n",
        "# ==========================================\n",
        "\n",
        "# 1. Carregar Dados Principais (Ligas)\n",
        "df_main = get_main_data(START_YEAR, END_YEAR)\n",
        "df_main['Date'] = pd.to_datetime(df_main['Date'], dayfirst=True, errors='coerce')\n",
        "df_main = df_main.dropna(subset=['Date'])\n",
        "\n",
        "# 2. Carregar xG e Champions League (Understat)\n",
        "if os.path.exists(XG_FILE):\n",
        "    print(\"üìÇ Carregando dados Understat locais...\")\n",
        "    df_understat = pd.read_csv(XG_FILE)\n",
        "else:\n",
        "    print(\"üåê A iniciar scraping Understat (Ligas + Champions)...\")\n",
        "    dfs = []\n",
        "    # Ligas\n",
        "    for y in range(START_YEAR, END_YEAR+1):\n",
        "        dfs.append(scrape_understat_season(y, 'EPL'))\n",
        "        dfs.append(scrape_understat_season(y, 'Bundesliga'))\n",
        "        dfs.append(scrape_understat_season(y, 'La_liga'))\n",
        "        dfs.append(scrape_understat_season(y, 'Ligue_1'))\n",
        "        dfs.append(scrape_understat_season(y, 'Serie_A'))\n",
        "        dfs.append(scrape_understat_season(y, 'Champions_League')) # <--- CL\n",
        "    \n",
        "    df_understat = pd.concat(dfs, ignore_index=True)\n",
        "    if not df_understat.empty:\n",
        "        df_understat['HomeTeam'] = df_understat['HomeTeam'].apply(clean_team_name)\n",
        "        df_understat['AwayTeam'] = df_understat['AwayTeam'].apply(clean_team_name)\n",
        "        df_understat.to_csv(XG_FILE, index=False)\n",
        "    else:\n",
        "        df_understat = pd.DataFrame()\n",
        "\n",
        "# 3. MERGE INTELIGENTE\n",
        "# O df_main tem as Odds das ligas. O df_understat tem xG e jogos da Champions.\n",
        "# Vamos usar o df_understat para enriquecer o df_main, e adicionar as linhas da Champions ao df_main.\n",
        "\n",
        "if not df_understat.empty:\n",
        "    df_understat['Date'] = pd.to_datetime(df_understat['Date']).dt.normalize()\n",
        "    df_main['Date'] = df_main['Date'].dt.normalize()\n",
        "    \n",
        "    # A) Separar Jogos da Liga vs Champions\n",
        "    # Jogos da Liga (Merge normal)\n",
        "    df_leagues = df_understat[df_understat['League'] != 'Champions_League']\n",
        "    \n",
        "    # Jogos da Champions (Temos de criar a estrutura para eles entrarem no dataset principal)\n",
        "    df_cl = df_understat[df_understat['League'] == 'Champions_League'].copy()\n",
        "    df_cl['Div'] = 'CL' # C√≥digo para Champions\n",
        "    \n",
        "    # No dataset principal, FTR (Full Time Result) √© H/D/A. Understat tem golos.\n",
        "    # Vamos calcular o FTR para a Champions\n",
        "    def get_res(row):\n",
        "        if row['FTHG'] > row['FTAG']: return 'H'\n",
        "        elif row['FTHG'] < row['FTAG']: return 'A'\n",
        "        else: return 'D'\n",
        "    df_cl['FTR'] = df_cl.apply(get_res, axis=1)\n",
        "    \n",
        "    # Preparar CL para concat (Selecionar colunas comuns)\n",
        "    cols_common = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'Div', 'Home_xG', 'Away_xG']\n",
        "    df_cl_clean = df_cl[cols_common]\n",
        "    \n",
        "    # B) Merge xG nas Ligas\n",
        "    print(\"üîÑ A realizar Merge (Ligas)...\")\n",
        "    # Limpar colunas antigas\n",
        "    cols_exclude = [c for c in df_main.columns if 'xG' in c]\n",
        "    df_main = df_main.drop(columns=cols_exclude)\n",
        "    \n",
        "    df_final = df_main.merge(\n",
        "        df_leagues[['Date', 'HomeTeam', 'AwayTeam', 'Home_xG', 'Away_xG']],\n",
        "        on=['Date', 'HomeTeam', 'AwayTeam'],\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # C) Adicionar Jogos da Champions (Append)\n",
        "    print(f\"üá™üá∫ A adicionar {len(df_cl_clean)} jogos da Champions League...\")\n",
        "    df_final = pd.concat([df_final, df_cl_clean], ignore_index=True)\n",
        "    \n",
        "else:\n",
        "    df_final = df_main.copy()\n",
        "\n",
        "# Ordenar tudo cronologicamente (Vital para o ELO funcionar bem)\n",
        "hoje = pd.Timestamp.now().normalize()\n",
        "df_final = df_final[df_final['Date'] <= hoje]\n",
        "df = df_final.sort_values(['Date']).reset_index(drop=True)\n",
        "df = df.fillna({'Home_xG': 1.0, 'Away_xG': 1.0})\n",
        "\n",
        "print(f\"‚úÖ Total Jogos (Big 5 + UCL): {len(df)}\")\n",
        "display(df.tail(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a02a0a",
      "metadata": {},
      "source": [
        "## 2. Feature Engineering Completa (ELO + Stats + Odds)\n",
        "\n",
        "Aqui adicionamos as colunas B365H, B365D, B365A (Odds da Bet365)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f923a5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Feature Engineering v7.0 - Champions League Logic]\n",
        "def feature_engineering(df):\n",
        "    print(\"‚öôÔ∏è Gerando Features (Com L√≥gica Champions League)...\")\n",
        "    df = df.copy()\n",
        "    \n",
        "    # 1. PREPARA√á√ÉO\n",
        "    df['Season'] = df['Date'].apply(lambda x: x.year if x.month > 7 else x.year - 1).astype(int)\n",
        "    df = df.sort_values('Date')\n",
        "    \n",
        "    le_div = LabelEncoder()\n",
        "    df['Div_Code'] = le_div.fit_transform(df['Div'])\n",
        "    print(f\"   Ligas: {le_div.classes_}\") # Verifica se 'CL' aparece aqui\n",
        "    \n",
        "    # ---------------------------------------------------------\n",
        "    # 2. MARKET VALUE\n",
        "    # ---------------------------------------------------------\n",
        "    real_values = {}\n",
        "    if os.path.exists('market_values.csv'):\n",
        "        try:\n",
        "            mv_df = pd.read_csv('market_values.csv')\n",
        "            mv_df.columns = [c.strip().capitalize() for c in mv_df.columns] \n",
        "            if 'Year' in mv_df.columns: mv_df.rename(columns={'Year': 'Season'}, inplace=True)\n",
        "            \n",
        "            if 'Season' in mv_df.columns and 'Value' in mv_df.columns:\n",
        "                def normalize_tm_name(name):\n",
        "                    name = str(name).lower()\n",
        "                    if 'manchester city' in name: return 'Man City'\n",
        "                    if 'manchester united' in name: return 'Man United'\n",
        "                    if 'paris saint-germain' in name: return 'Paris Saint Germain'\n",
        "                    if 'leverkusen' in name: return 'Bayer Leverkusen'\n",
        "                    if 'monchengladbach' in name: return 'Borussia M.Gladbach'\n",
        "                    if 'inter' in name: return 'Inter'\n",
        "                    if 'milan' in name: return 'AC Milan'\n",
        "                    if 'sporting cp' in name: return 'Sporting CP'\n",
        "                    if 'benfica' in name: return 'Benfica'\n",
        "                    if 'porto' in name: return 'Porto'\n",
        "                    return name \n",
        "                \n",
        "                for _, row in mv_df.iterrows():\n",
        "                    try: s = int(row['Season'])\n",
        "                    except: continue\n",
        "                    t = normalize_tm_name(row['Team'])\n",
        "                    v = row['Value']\n",
        "                    if s not in real_values: real_values[s] = {}\n",
        "                    real_values[s][t] = v\n",
        "                    real_values[s][row['Team']] = v \n",
        "        except: pass\n",
        "\n",
        "    def get_market_value(team, season):\n",
        "        if season in real_values:\n",
        "            if team in real_values[season]: return real_values[season][team]\n",
        "            tc = clean_team_name(team) \n",
        "            if tc in real_values[season]: return real_values[season][tc]\n",
        "            for key in real_values[season]:\n",
        "                if isinstance(key, str) and (team in key or key in team): return real_values[season][key]\n",
        "\n",
        "        tier_1 = ['Man City', 'Arsenal', 'Liverpool', 'Real Madrid', 'Barcelona', 'Bayern Munich', 'Paris Saint Germain', 'Inter']\n",
        "        tier_2 = ['Man United', 'Chelsea', 'Tottenham', 'Newcastle', 'Atletico Madrid', 'Borussia Dortmund', 'Bayer Leverkusen', 'RB Leipzig', 'Juventus', 'AC Milan', 'Napoli', 'Benfica', 'Porto', 'Sporting CP']\n",
        "        if team in tier_1: return 900\n",
        "        if team in tier_2: return 500\n",
        "        return 150 \n",
        "\n",
        "    df['Home_Value'] = df.apply(lambda x: get_market_value(x['HomeTeam'], x['Season']), axis=1)\n",
        "    df['Away_Value'] = df.apply(lambda x: get_market_value(x['AwayTeam'], x['Season']), axis=1)\n",
        "    df['Value_Ratio'] = np.log1p(df['Home_Value']) - np.log1p(df['Away_Value'])\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 3. PONTOS E MOTIVA√á√ÉO (Adaptado para CL)\n",
        "    # ---------------------------------------------------------\n",
        "    standings = {} \n",
        "    df['Home_Pts'] = 0; df['Away_Pts'] = 0\n",
        "    df['Home_Pos'] = 10; df['Away_Pos'] = 10\n",
        "    df['Home_Game_Num'] = 0; df['Away_Game_Num'] = 0\n",
        "    \n",
        "    # Feature: Tipo de Competi√ß√£o (0=Liga, 1=Ta√ßa/CL)\n",
        "    df['Is_Cup'] = df['Div'].apply(lambda x: 1 if x == 'CL' else 0)\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        season = row['Season']\n",
        "        div = row['Div']\n",
        "        h, a, res = row['HomeTeam'], row['AwayTeam'], row['FTR']\n",
        "        \n",
        "        if season not in standings: standings[season] = {}\n",
        "        if div not in standings[season]: standings[season][div] = {}\n",
        "        if h not in standings[season][div]: standings[season][div][h] = {'pts': 0, 'games': 0}\n",
        "        if a not in standings[season][div]: standings[season][div][a] = {'pts': 0, 'games': 0}\n",
        "        \n",
        "        # S√≥ usamos pontos se for Liga. Se for CL, pomos dummy (0)\n",
        "        if div != 'CL':\n",
        "            df.at[i, 'Home_Pts'] = standings[season][div][h]['pts']\n",
        "            df.at[i, 'Away_Pts'] = standings[season][div][a]['pts']\n",
        "            \n",
        "            teams_sorted = sorted(standings[season][div].items(), key=lambda x: x[1]['pts'], reverse=True)\n",
        "            ranks = {t: r+1 for r, (t, data) in enumerate(teams_sorted)}\n",
        "            df.at[i, 'Home_Pos'] = ranks.get(h, 10)\n",
        "            df.at[i, 'Away_Pos'] = ranks.get(a, 10)\n",
        "        else:\n",
        "            df.at[i, 'Home_Pts'] = 0\n",
        "            df.at[i, 'Away_Pts'] = 0\n",
        "            df.at[i, 'Home_Pos'] = 1 # Dummy, na CL todos querem ganhar\n",
        "            df.at[i, 'Away_Pos'] = 1\n",
        "            \n",
        "        df.at[i, 'Home_Game_Num'] = standings[season][div][h]['games'] + 1\n",
        "        df.at[i, 'Away_Game_Num'] = standings[season][div][a]['games'] + 1\n",
        "        \n",
        "        pts_h = 3 if res == 'H' else 1 if res == 'D' else 0\n",
        "        pts_a = 3 if res == 'A' else 1 if res == 'D' else 0\n",
        "        standings[season][div][h]['pts'] += pts_h\n",
        "        standings[season][div][a]['pts'] += pts_a\n",
        "        standings[season][div][h]['games'] += 1\n",
        "        standings[season][div][a]['games'] += 1\n",
        "\n",
        "    def get_motivation(game_num, pos, is_cup):\n",
        "        if is_cup: return 1.3 # Champions League = Motiva√ß√£o M√°xima\n",
        "        if game_num < 30: return 1.0 \n",
        "        if pos <= 6: return 1.2 \n",
        "        if pos >= 16: return 1.3 \n",
        "        return 0.5 \n",
        "\n",
        "    df['Home_Motiv'] = df.apply(lambda x: get_motivation(x['Home_Game_Num'], x['Home_Pos'], x['Is_Cup']), axis=1)\n",
        "    df['Away_Motiv'] = df.apply(lambda x: get_motivation(x['Away_Game_Num'], x['Away_Pos'], x['Is_Cup']), axis=1)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 4. FADIGA E ELO\n",
        "    # ---------------------------------------------------------\n",
        "    df['Rest_Home'] = df.groupby('HomeTeam')['Date'].diff().dt.days.fillna(7).clip(upper=15)\n",
        "    df['Rest_Away'] = df.groupby('AwayTeam')['Date'].diff().dt.days.fillna(7).clip(upper=15)\n",
        "    \n",
        "    def check_euro_fatigue(rest, value):\n",
        "        if value > 400 and rest < 4: return 1\n",
        "        return 0\n",
        "\n",
        "    df['Home_Fatigue'] = df.apply(lambda x: check_euro_fatigue(x['Rest_Home'], x['Home_Value']), axis=1)\n",
        "    df['Away_Fatigue'] = df.apply(lambda x: check_euro_fatigue(x['Rest_Away'], x['Away_Value']), axis=1)\n",
        "\n",
        "    df['HomeElo'] = 1500.0; df['AwayElo'] = 1500.0\n",
        "    elo_dict = {}\n",
        "    k_factor = 20\n",
        "    \n",
        "    # ELO √© Global (mistura ligas e CL)\n",
        "    for i, row in df.iterrows():\n",
        "        h, a, res = row['HomeTeam'], row['AwayTeam'], row['FTR']\n",
        "        h_elo = elo_dict.get(h, 1500.0); a_elo = elo_dict.get(a, 1500.0)\n",
        "        df.at[i, 'HomeElo'] = h_elo; df.at[i, 'AwayElo'] = a_elo\n",
        "        actual = 1 if res == 'H' else 0.5 if res == 'D' else 0\n",
        "        exp = 1 / (1 + 10**((a_elo - h_elo)/400))\n",
        "        elo_dict[h] = h_elo + k_factor * (actual - exp)\n",
        "        elo_dict[a] = a_elo - k_factor * (actual - exp)\n",
        "        \n",
        "    df['EloDiff'] = df['HomeElo'] - df['AwayElo']\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 5. ROLLING STATS\n",
        "    # ---------------------------------------------------------\n",
        "    # Na CL, muitas vezes faltam dados de Cantos/Cart√µes no CSV. \n",
        "    # Vamos focar no que temos: Golos e xG.\n",
        "    cols_to_avg = ['FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'Home_xG', 'Away_xG']\n",
        "    cols_to_avg = [c for c in cols_to_avg if c in df.columns]\n",
        "    \n",
        "    home_stats = df[['Date', 'HomeTeam'] + cols_to_avg].rename(columns={'HomeTeam': 'Team'})\n",
        "    away_stats = df[['Date', 'AwayTeam'] + cols_to_avg].rename(columns={'AwayTeam': 'Team'})\n",
        "    \n",
        "    for col in cols_to_avg:\n",
        "        home_stats.rename(columns={col: f'Stat_{col}'}, inplace=True)\n",
        "        away_stats.rename(columns={col: f'Stat_{col}'}, inplace=True)\n",
        "\n",
        "    all_stats = pd.concat([home_stats, away_stats]).sort_values(['Team', 'Date'])\n",
        "    \n",
        "    for col in [c for c in all_stats.columns if 'Stat_' in c]:\n",
        "        all_stats[f'Avg_{col}_L5'] = all_stats.groupby('Team')[col].transform(lambda x: x.shift(1).rolling(5, min_periods=3).mean()).fillna(0)\n",
        "    \n",
        "    feat_cols = ['Date', 'Team'] + [c for c in all_stats.columns if 'Avg_' in c]\n",
        "    df = df.merge(all_stats[feat_cols], left_on=['Date', 'HomeTeam'], right_on=['Date', 'Team'], how='left').drop(columns=['Team'])\n",
        "    df = df.rename(columns={c: f'Home_{c}' for c in feat_cols if 'Avg_' in c})\n",
        "    df = df.merge(all_stats[feat_cols], left_on=['Date', 'AwayTeam'], right_on=['Date', 'Team'], how='left').drop(columns=['Team'])\n",
        "    df = df.rename(columns={c: f'Away_{c}' for c in feat_cols if 'Avg_' in c})\n",
        "\n",
        "    # Odds Features (Preencher com 0 se for jogo da CL sem odds, para n√£o partir o c√≥digo)\n",
        "    if 'B365H' not in df.columns: df['B365H'] = 0\n",
        "    if 'B365D' not in df.columns: df['B365D'] = 0\n",
        "    if 'B365A' not in df.columns: df['B365A'] = 0\n",
        "    \n",
        "    df['Imp_Home'] = np.where(df['B365H']>0, 1/df['B365H'], 0)\n",
        "    df['Imp_Draw'] = np.where(df['B365D']>0, 1/df['B365D'], 0)\n",
        "    df['Imp_Away'] = np.where(df['B365A']>0, 1/df['B365A'], 0)\n",
        "    \n",
        "    # 1X / X2 (Estimativa)\n",
        "    df['Imp_1X'] = df['Imp_Home'] + df['Imp_Draw']\n",
        "    df['Imp_X2'] = df['Imp_Draw'] + df['Imp_Away']\n",
        "    df['Imp_12'] = df['Imp_Home'] + df['Imp_Away']\n",
        "\n",
        "    # LISTA FINAL\n",
        "    features_needed = [\n",
        "        'Div_Code', 'Is_Cup', # <--- NOVO\n",
        "        'HomeElo', 'AwayElo', 'EloDiff', \n",
        "        'Rest_Home', 'Rest_Away', \n",
        "        'Home_Value', 'Away_Value', 'Value_Ratio',\n",
        "        'Home_Fatigue', 'Away_Fatigue', 'Home_Motiv', 'Away_Motiv',\n",
        "        'Imp_Home', 'Imp_Draw', 'Imp_Away',\n",
        "        'Imp_1X', 'Imp_X2', 'Imp_12',\n",
        "        'Home_Pts', 'Away_Pts', 'Home_Pos', 'Away_Pos'\n",
        "    ]\n",
        "    features_needed += [c for c in df.columns if 'Home_Avg_' in c or 'Away_Avg_' in c]\n",
        "    features_needed = list(set(features_needed))\n",
        "    existing_features = [f for f in features_needed if f in df.columns]\n",
        "    \n",
        "    print(\"üßπ Limpeza Final (Removendo jogos sem Odds para Treino)...\")\n",
        "    # Para treino, s√≥ queremos jogos com Odds (Ligas). A CL serviu para calcular ELO/Stats.\n",
        "    df_clean = df.dropna(subset=['FTR']).copy()\n",
        "    # Filtro importante: s√≥ manter se tiver odds v√°lidas OU se for para infer√™ncia futura\n",
        "    df_clean = df_clean[df_clean['Imp_Home'] > 0] \n",
        "    \n",
        "    df_clean[existing_features] = df_clean[existing_features].fillna(0)\n",
        "    df_clean.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "    \n",
        "    return df_clean, existing_features, elo_dict, le_div\n",
        "\n",
        "df_ready, features, current_elos, le_div = feature_engineering(df)\n",
        "print(f\"‚úÖ Features updated. Total features: {len(features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f5a89c",
      "metadata": {},
      "source": [
        "## 3. Prepara√ß√£o e Treino do Modelo\n",
        "Treino Intensivo: Grid Search (Hyperparameter Tuning) Aqui √© onde \"apertamos\" o modelo. Vamos testar v√°rias combina√ß√µes. Nota: Isto pode demorar 2 ou 3 minutos a correr."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c2e9837",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Treino Otimizado TOTAL - Imports Corrigidos]\n",
        "\n",
        "# Limpeza de Seguran√ßa\n",
        "print(\"üßπ A limpar valores infinitos/nulos...\")\n",
        "df_ready.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "df_ready.fillna(0, inplace=True)\n",
        "\n",
        "# 1. Preparar Dados\n",
        "target = 'Target'\n",
        "le = LabelEncoder()\n",
        "df_ready['Target'] = le.fit_transform(df_ready['FTR']) # 0=Away, 1=Draw, 2=Home\n",
        "\n",
        "# Split 80/20\n",
        "split_index = int(len(df_ready) * 0.80)\n",
        "train = df_ready.iloc[:split_index]\n",
        "test = df_ready.iloc[split_index:]\n",
        "\n",
        "X_train, y_train = train[features], train['Target']\n",
        "X_test, y_test = test[features], test['Target']\n",
        "\n",
        "print(f\"üèãÔ∏è A iniciar Otimiza√ß√£o Dupla em {len(X_train)} jogos...\")\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "# --- 1. MODELO NORMAL ---\n",
        "print(\"\\nüîç A otimizar Modelo Normal (1X2)...\")\n",
        "xgb_multi = xgb.XGBClassifier(objective='multi:softprob', random_state=42, eval_metric='mlogloss')\n",
        "param_grid_multi = {'n_estimators': [200, 300], 'max_depth': [3, 4], 'learning_rate': [0.01, 0.03], 'subsample': [0.8]}\n",
        "\n",
        "grid_multi = GridSearchCV(estimator=xgb_multi, param_grid=param_grid_multi, cv=tscv, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
        "\n",
        "sample_weights = np.ones(len(y_train))\n",
        "draw_code = le.transform(['D'])[0]\n",
        "sample_weights[y_train == draw_code] = 1.15\n",
        "\n",
        "grid_multi.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "model_multi = grid_multi.best_estimator_\n",
        "print(f\"‚úÖ Melhores Params (Normal): {grid_multi.best_params_}\")\n",
        "\n",
        "# --- 2. MODELO SNIPER ---\n",
        "print(\"\\nüîç A otimizar Modelo Sniper (Bin√°rio)...\")\n",
        "y_train_win = (y_train == 2).astype(int); y_test_win = (y_test == 2).astype(int)\n",
        "xgb_sniper = xgb.XGBClassifier(objective='binary:logistic', random_state=42, eval_metric='logloss')\n",
        "param_grid_sniper = {'n_estimators': [150, 200, 250], 'max_depth': [3, 4, 5], 'learning_rate': [0.01, 0.02, 0.03], 'subsample': [0.8]}\n",
        "\n",
        "grid_sniper = GridSearchCV(estimator=xgb_sniper, param_grid=param_grid_sniper, cv=tscv, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
        "grid_sniper.fit(X_train, y_train_win)\n",
        "model_sniper = grid_sniper.best_estimator_\n",
        "print(f\"‚úÖ Melhores Params (Sniper): {grid_sniper.best_params_}\")\n",
        "\n",
        "# --- 3. MODELO SHIELD ---\n",
        "print(\"\\nüõ°Ô∏è A treinar Modelo Shield...\")\n",
        "y_train_1x = (y_train != 0).astype(int)\n",
        "model_shield = xgb.XGBClassifier(**grid_sniper.best_params_, objective='binary:logistic', random_state=42)\n",
        "model_shield.fit(X_train, y_train_1x)\n",
        "\n",
        "# --- 4. VISUALIZA√á√ÉO ---\n",
        "print(\"\\nüìä RELAT√ìRIO VISUAL FINAL\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "preds_multi = model_multi.predict(X_test)\n",
        "acc_multi = accuracy_score(y_test, preds_multi)\n",
        "cm_multi = confusion_matrix(y_test, preds_multi)\n",
        "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues', xticklabels=['Away', 'Draw', 'Home'], yticklabels=['Away', 'Draw', 'Home'], ax=axes[0])\n",
        "axes[0].set_title(f'Modelo Normal (Acc: {acc_multi:.1%})')\n",
        "\n",
        "preds_sniper = model_sniper.predict(X_test)\n",
        "acc_sniper = accuracy_score(y_test_win, preds_sniper)\n",
        "cm_sniper = confusion_matrix(y_test_win, preds_sniper)\n",
        "sns.heatmap(cm_sniper, annot=True, fmt='d', cmap='Greens', xticklabels=['Not Win', 'Win'], yticklabels=['Not Win', 'Win'], ax=axes[1])\n",
        "axes[1].set_title(f'Modelo Sniper (Acc: {acc_sniper:.1%})')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1c0479",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Feature Importance]\n",
        "feature_imp = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': model_multi.feature_importances_\n",
        "}).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"üìã TOP FEATURES (General Model):\")\n",
        "feature_imp['Importance %'] = (feature_imp['Importance'] * 100).round(2)\n",
        "display(feature_imp[['Feature', 'Importance %']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7176fed1",
      "metadata": {},
      "source": [
        "## 4. Aplica√ß√£o na \"Vida Real\"\n",
        "Aqui est√° a fun√ß√£o final. Ela usa o dicion√°rio `current_elo` (que cont√©m os valores mais recentes ap√≥s o √∫ltimo jogo do dataset) para fazer previs√µes sobre jogos futuros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae7c1481",
      "metadata": {},
      "outputs": [],
      "source": [
        "# [CELL: Prediction Function v8.1 - Valida√ß√£o de Ligas (Anti-Erro)]\n",
        "def predict_match_advanced(date_str, home_team, away_team, \n",
        "                           odd_h, odd_d, odd_a, \n",
        "                           division='E0', # OBRIGAT√ìRIO\n",
        "                           odd_1x=None, odd_12=None, odd_x2=None):\n",
        "    \n",
        "    match_date = pd.to_datetime(date_str)\n",
        "    \n",
        "    div_map = {\n",
        "        'E0': 'Premier League üá¨üáß', 'D1': 'Bundesliga üá©üá™', \n",
        "        'SP1': 'La Liga üá™üá∏', 'F1': 'Ligue 1 üá´üá∑', \n",
        "        'I1': 'Serie A üáÆüáπ', 'CL': 'Champions League üá™üá∫'\n",
        "    }\n",
        "    div_name = div_map.get(division, division)\n",
        "    \n",
        "    # --- 0. VALIDA√á√ÉO DE SEGURAN√áA (NOVO!) ---\n",
        "    # Criar mapa de equipas -> liga (baseado no hist√≥rico recente)\n",
        "    # Se a equipa jogou 90% dos jogos na liga X, ela √© da liga X.\n",
        "    if division != 'CL': # Na Champions vale tudo\n",
        "        print(\"üõ°Ô∏è A validar equipas...\")\n",
        "        for team in [home_team, away_team]:\n",
        "            # Verificar √∫ltimos 20 jogos da equipa\n",
        "            team_games = df_ready[(df_ready['HomeTeam'] == team) | (df_ready['AwayTeam'] == team)].tail(20)\n",
        "            if not team_games.empty:\n",
        "                # Contar ligas onde jogou (excluindo CL)\n",
        "                leagues = team_games[team_games['Div'] != 'CL']['Div'].value_counts()\n",
        "                if not leagues.empty:\n",
        "                    main_league = leagues.index[0] # A liga mais comum\n",
        "                    if main_league != division:\n",
        "                        print(f\"‚ùå ERRO CR√çTICO: {team} joga na {div_map.get(main_league, main_league)}, n√£o na {div_name}!\")\n",
        "                        print(\"   -> Corre a fun√ß√£o com a divis√£o correta ou muda a equipa.\")\n",
        "                        return # P√°ra a fun√ß√£o aqui\n",
        "\n",
        "    print(f\"\\nüîÆ PREVIS√ÉO AVAN√áADA ({div_name}): {home_team} vs {away_team} ({date_str})\")\n",
        "    print(\"=\" * 100)\n",
        "    \n",
        "    past_data = df_ready[df_ready['Date'] < match_date].copy()\n",
        "    if past_data.empty: \n",
        "        print(\"‚ö†Ô∏è Erro: Sem dados hist√≥ricos suficientes.\")\n",
        "        return\n",
        "\n",
        "    # --- 1. CONTEXTO & FEATURES ---\n",
        "    def get_market_value(team):\n",
        "        team_games = past_data[(past_data['HomeTeam'] == team) | (past_data['AwayTeam'] == team)]\n",
        "        if not team_games.empty:\n",
        "            last = team_games.iloc[-1]\n",
        "            if last['HomeTeam'] == team: return last.get('Home_Value', 150)\n",
        "            return last.get('Away_Value', 150)\n",
        "        # Fallback\n",
        "        tier_1 = ['Man City', 'Real Madrid', 'Bayern Munich', 'Paris Saint Germain', 'Inter']\n",
        "        if team in tier_1: return 800\n",
        "        return 200\n",
        "\n",
        "    def get_context(team):\n",
        "        team_games = past_data[(past_data['HomeTeam'] == team) | (past_data['AwayTeam'] == team)]\n",
        "        if team_games.empty: return 0.5, 10, 7\n",
        "        last = team_games.iloc[-1]\n",
        "        pos = last['Home_Pos'] if last['HomeTeam'] == team else last['Away_Pos']\n",
        "        games = len(team_games)\n",
        "        rest = (match_date - last['Date']).days\n",
        "        \n",
        "        # Motiva√ß√£o baseada na competi√ß√£o\n",
        "        if division == 'CL':\n",
        "            motiv = 1.3\n",
        "        else:\n",
        "            motiv = 1.0\n",
        "            if games > 28: \n",
        "                if pos > 6 and pos < 16: motiv = 0.5 \n",
        "                else: motiv = 1.2 \n",
        "        return motiv, pos, rest\n",
        "\n",
        "    input_data = {}\n",
        "    \n",
        "    h_motiv, h_pos, h_rest = get_context(home_team)\n",
        "    a_motiv, a_pos, a_rest = get_context(away_team)\n",
        "    h_val = get_market_value(home_team)\n",
        "    a_val = get_market_value(away_team)\n",
        "    \n",
        "    input_data['Home_Motiv'] = h_motiv; input_data['Away_Motiv'] = a_motiv\n",
        "    input_data['Rest_Home'] = h_rest; input_data['Rest_Away'] = a_rest\n",
        "    input_data['Home_Value'] = h_val; input_data['Away_Value'] = a_val\n",
        "    input_data['Value_Ratio'] = np.log1p(h_val) - np.log1p(a_val)\n",
        "    input_data['Is_Cup'] = 1 if division == 'CL' else 0\n",
        "    input_data['Home_Fatigue'] = 1 if (h_val > 400 and h_rest < 4) else 0\n",
        "    input_data['Away_Fatigue'] = 1 if (a_val > 400 and a_rest < 4) else 0\n",
        "    \n",
        "    h_elo = current_elos.get(home_team, 1500)\n",
        "    a_elo = current_elos.get(away_team, 1500)\n",
        "    input_data['HomeElo'] = h_elo; input_data['AwayElo'] = a_elo\n",
        "    input_data['EloDiff'] = h_elo - a_elo\n",
        "    input_data['Home_Pts'] = 0; input_data['Away_Pts'] = 0\n",
        "    input_data['Home_Pos'] = h_pos; input_data['Away_Pos'] = a_pos\n",
        "    \n",
        "    try: input_data['Div_Code'] = le_div.transform([division])[0]\n",
        "    except: input_data['Div_Code'] = 0\n",
        "    \n",
        "    # Odds\n",
        "    input_data['Imp_Home'] = 1/odd_h; input_data['Imp_Draw'] = 1/odd_d; input_data['Imp_Away'] = 1/odd_a\n",
        "    input_data['Imp_1X'] = 1/odd_1x if odd_1x else (1/odd_h + 1/odd_d)\n",
        "    input_data['Imp_X2'] = 1/odd_x2 if odd_x2 else (1/odd_d + 1/odd_a)\n",
        "    input_data['Imp_12'] = 1/odd_12 if odd_12 else (1/odd_h + 1/odd_a)\n",
        "    \n",
        "    # Stats\n",
        "    def fill_stats(team, prefix_h, prefix_a):\n",
        "        games = past_data[(past_data['HomeTeam'] == team) | (past_data['AwayTeam'] == team)]\n",
        "        if games.empty: return\n",
        "        last = games.iloc[-1]\n",
        "        for f in features:\n",
        "            if 'Avg_' in f:\n",
        "                try:\n",
        "                    clean = \"\"\n",
        "                    val = 0\n",
        "                    if prefix_h in f: \n",
        "                        clean = f.replace(prefix_h, \"\")\n",
        "                        col_name = f\"Home_{clean}\"\n",
        "                        if col_name in last: val = last[col_name] if last['HomeTeam'] == team else last.get(f\"Away_{clean}\", 0)\n",
        "                    elif prefix_a in f:\n",
        "                        clean = f.replace(prefix_a, \"\")\n",
        "                        col_name = f\"Home_{clean}\"\n",
        "                        if col_name in last: val = last[col_name] if last['HomeTeam'] == team else last.get(f\"Away_{clean}\", 0)\n",
        "                    if clean: input_data[f] = val\n",
        "                except: pass \n",
        "\n",
        "    fill_stats(home_team, \"Home_\", \"XX_IGNORE_XX\")\n",
        "    fill_stats(away_team, \"XX_IGNORE_XX\", \"Away_\")\n",
        "\n",
        "    for f in features: \n",
        "        if f not in input_data: input_data[f] = df_ready[f].mean()\n",
        "\n",
        "    # --- 2. EXECU√á√ÉO ---\n",
        "    X_new = pd.DataFrame([input_data])[features]\n",
        "    probs = model_multi.predict_proba(X_new)[0] \n",
        "    prob_a, prob_d, prob_h = probs[0], probs[1], probs[2]\n",
        "    conf_win = model_sniper.predict_proba(X_new)[0][1]\n",
        "    try: conf_shield = model_shield.predict_proba(X_new)[0][1]\n",
        "    except: conf_shield = prob_h + prob_d\n",
        "    \n",
        "    # --- 3. RELAT√ìRIO VISUAL ---\n",
        "    print(f\"üìä PROBABILIDADES (IA):\")\n",
        "    print(f\"   üè† Casa: {prob_h:.1%} (Sniper: {conf_win:.1%})\")\n",
        "    print(f\"   ü§ù Empate: {prob_d:.1%}\")\n",
        "    print(f\"   ‚úàÔ∏è Fora: {prob_a:.1%}\")\n",
        "    print(\"-\" * 100)\n",
        "\n",
        "    opportunities = []\n",
        "\n",
        "    def analyze(name, odd, prob, bet_type=\"Standard\"):\n",
        "        if not odd or odd <= 1: return\n",
        "        implied_prob = 1 / odd \n",
        "        fair_odd = 1 / prob if prob > 0 else 99.0\n",
        "        ev = (prob * odd) - 1\n",
        "        status = \"üíé VALOR!\" if ev > 0 else (\"‚úÖ JUSTO\" if ev > -0.05 else \"‚ùå FRACO\")\n",
        "        print(f\"   ‚Ä¢ {name:<35} | Odd: {odd:.2f} ({implied_prob:.1%}) | IA: {fair_odd:.2f} ({prob:.1%}) | {status}\")\n",
        "        opportunities.append({\"name\": name, \"odd\": odd, \"prob\": prob, \"ev\": ev})\n",
        "\n",
        "    print(\"üí∞ SCANNER DE MERCADO (Compara√ß√£o de Percentagens):\")\n",
        "    analyze(f\"Vitoria {home_team}\", odd_h, prob_h, \"HOME\")\n",
        "    analyze(\"Empate\", odd_d, prob_d, \"DRAW\")\n",
        "    analyze(f\"Vitoria {away_team}\", odd_a, prob_a, \"AWAY\")\n",
        "    \n",
        "    prob_1x_val = ((prob_h + prob_d) + conf_win) / 2\n",
        "    try: prob_1x_val = (prob_1x_val + conf_shield) / 2\n",
        "    except: pass\n",
        "\n",
        "    if odd_1x: analyze(f\"DC 1X ({home_team} ou Empate)\", odd_1x, prob_1x_val, \"1X\")\n",
        "    if odd_x2: analyze(f\"DC X2 ({away_team} ou Empate)\", odd_x2, (prob_a + prob_d), \"X2\")\n",
        "    if odd_12: analyze(f\"DC 12 ({home_team} ou {away_team})\", odd_12, (prob_h + prob_a), \"12\")\n",
        "\n",
        "    print(\"-\" * 100)\n",
        "    \n",
        "    # --- 4. VEREDICTO FINAL ---\n",
        "    opportunities.sort(key=lambda x: x['ev'], reverse=True)\n",
        "    best = opportunities[0]\n",
        "    \n",
        "    most_likely = sorted(opportunities, key=lambda x: x['prob'], reverse=True)[0]\n",
        "    final_pick = best\n",
        "    reason = \"Melhor valor matem√°tico dispon√≠vel (EV Positivo).\"\n",
        "    \n",
        "    if most_likely['prob'] > 0.65 and best['ev'] < 0.05:\n",
        "        final_pick = most_likely\n",
        "        reason = f\"Probabilidade Dominante ({final_pick['prob']:.1%}). Aposta 'Banker'.\"\n",
        "\n",
        "    print(f\"üèÜ ESCOLHA RACIONAL (Dinheiro): üëâ {final_pick['name']} (Odd: {final_pick['odd']})\")\n",
        "    print(f\"   üìù Motivo: {reason}\")\n",
        "    print(f\"   üìâ Confian√ßa IA: {final_pick['prob']:.1%}\")\n",
        "    print(\"\")\n",
        "    \n",
        "    if most_likely['name'] != final_pick['name']:\n",
        "        print(f\"üé≤ RESULTADO MAIS PROV√ÅVEL:   üëâ {most_likely['name']} ({most_likely['prob']:.1%})\")\n",
        "        print(\"   ‚ö†Ô∏è Nota: Este √© o desfecho que a IA acha que vai acontecer, mas a Odd paga pouco.\")\n",
        "    else:\n",
        "        print(\"üé≤ RESULTADO MAIS PROV√ÅVEL:   (Igual √† Escolha Racional)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b815bf26",
      "metadata": {},
      "outputs": [],
      "source": [
        "predict_match_advanced('2025-12-09', 'Inter', 'Liverpool', \n",
        "                       odd_h=2.02, odd_d=3.60, odd_a=3.25, \n",
        "                       division='CL',\n",
        "                       odd_1x=1.30, odd_12=1.25, odd_x2=1.65)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e9ab23",
      "metadata": {},
      "outputs": [],
      "source": [
        "predict_match_advanced('2025-12-08', 'Torino', 'Milan', \n",
        "                       odd_h=5.25, odd_d=3.70, odd_a=1.61, \n",
        "                       division='I1',\n",
        "                       odd_1x=2.12, odd_12=1.24, odd_x2=1.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f413ae3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "predict_match_advanced('2025-12-08', 'Wolves', 'Man United', \n",
        "                       odd_h=5.00, odd_d=4.20, odd_a=1.56, \n",
        "                       division='E0', \n",
        "                       odd_1x=2.25, odd_12=1.19, odd_x2=1.15)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
